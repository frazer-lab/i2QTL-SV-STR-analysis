{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/djakubosky/software/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import djPyBio as DJ\n",
    "from djPyBio import Common as CM\n",
    "from djPyBio import mpltools as axtools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import pybedtools as pbt\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "import itertools\n",
    "import tempfile\n",
    "import six\n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from mpl_toolkits.axes_grid1 import  make_axes_locatable\n",
    "import datetime\n",
    "\n",
    "import argparse\n",
    "from scipy.stats import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pedigree_280 = pd.read_pickle('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/private_output/pedigree_analysis_unrelateds/pedigree_280.pkl') # 2017_07_26_11AM\n",
    "\n",
    "# unrelated_set = pedigree_280[pedigree_280.In_Unrelated_Set == 'Yes'].WGS_UUID.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_div(x, y, alt=0):\n",
    "    try:\n",
    "        return x/y\n",
    "    except:\n",
    "        return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_minor_allele_freq(tran, uuids, chrom_dict, sex_dict):\n",
    "    \n",
    "    \n",
    "    nnref_col = []\n",
    "    ref_col = []\n",
    "    ref_uuids_col = []\n",
    "    nnref_uuids_col = []\n",
    "    alt_allele_freq = []\n",
    "    ref_allele_freq = []\n",
    "    minor_allele_freq = []\n",
    "    minor_allele = []\n",
    "    missing_col = []\n",
    "    alleles_dist_col = []\n",
    "\n",
    "    for c in tran.columns:\n",
    "        chrom = chrom_dict[c]\n",
    "        l = tran[c].tolist()\n",
    "        \n",
    "        #uuids containing the 1 allele\n",
    "        non_ref = 0\n",
    "        non_ref_uuids = []\n",
    "        \n",
    "        #uuids containing the 0 allele \n",
    "        ref = 0\n",
    "        ref_uuids = []\n",
    "        \n",
    "        ref_allele = 0\n",
    "        alt_allele = 0\n",
    "        missing = 0\n",
    "        # for chroms that are diploid\n",
    "        # correct for allelic probs on sex chroms\n",
    "        gts_dict = {'0/0':0, '0/1':1, '1/1':2, './.':0}\n",
    "        gts_dict_sex = {'0/0':0, '0/1':1, '1/1':1, './.':0}\n",
    "        alleles_dist = {}\n",
    "        \n",
    "        count = 0\n",
    "        for c in l:\n",
    "            uuid = uuids[count]\n",
    "            sex = sex_dict[uuid]\n",
    "            \n",
    "            c = copy.deepcopy(str(c))\n",
    "            alleles_dist[c] = alleles_dist.get(c, 0) + 1\n",
    "            \n",
    "            if c == './.':\n",
    "                missing +=1\n",
    "                continue\n",
    "            \n",
    "            if chrom=='Y':\n",
    "                if sex == 'M':\n",
    "                    aa = gts_dict_sex[c]\n",
    "                    ra = 1 - aa\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            elif chrom=='X':\n",
    "                if sex == 'M':\n",
    "                    aa = gts_dict_sex[c]\n",
    "                    ra = 1 - aa\n",
    "                else:\n",
    "                    aa = gts_dict[c]\n",
    "                    ra = 2 - aa\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    aa = gts_dict[c]\n",
    "                except:\n",
    "                    print c\n",
    "                    break\n",
    "                ra = 2 - aa\n",
    "#                 ref_allele += ra\n",
    "#                 alt_allele += aa\n",
    "            \n",
    "            ref_allele += ra\n",
    "            alt_allele += aa\n",
    "                \n",
    "           \n",
    "            if c not in ['0/0','./.']:\n",
    "                non_ref +=1\n",
    "                non_ref_uuids.append(uuids[count])\n",
    "\n",
    "            if c == '0/0':\n",
    "                ref +=1\n",
    "                ref_uuids.append(uuids[count])\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "            count +=1\n",
    "        \n",
    "        # fix alleles dist for any missing gt types\n",
    "        \n",
    "        allele_types = ['0/0', '0/1', '1/1', './.']\n",
    "        for a in allele_types:\n",
    "            alleles_dist[a] = alleles_dist.get(a, 0)\n",
    "        \n",
    "        \n",
    "        alleles_dist_col.append(alleles_dist)\n",
    "        missing_col.append(missing)\n",
    "        nnref_col.append(non_ref)\n",
    "        nnref_uuids_col.append(non_ref_uuids)\n",
    "             \n",
    "        ref_col.append(ref)\n",
    "        ref_uuids_col.append(ref_uuids)\n",
    "        \n",
    "        \n",
    "        \n",
    "        tot_alleles = ref_allele + alt_allele\n",
    "        \n",
    "        \n",
    "        ref_af = safe_div(ref_allele, tot_alleles, alt='All Missing')\n",
    "        alt_af = safe_div(alt_allele, tot_alleles, alt='All Missing')\n",
    "        \n",
    "#         ref_af = ref_allele/tot_alleles\n",
    "#         alt_af = alt_allele/tot_alleles\n",
    "        \n",
    "        afs = [ref_af, alt_af]\n",
    "        maf = min(afs)\n",
    "        \n",
    "        if afs.index(maf) == 0:\n",
    "            minor_allele.append('REF')\n",
    "        else:\n",
    "            minor_allele.append('ALT')\n",
    "        \n",
    "        minor_allele_freq.append(maf)\n",
    "        ref_allele_freq.append(ref_af)\n",
    "        alt_allele_freq.append(alt_af)\n",
    "        \n",
    "    \n",
    "    out_names = ['NNREF', 'NNREF_UUIDs','ALTAF', 'REFAF', 'MAF', 'Minor_Allele', 'NREF', 'REF_UUIDS', 'Missing', 'Alleles_Dist']\n",
    "    out_data = [nnref_col, nnref_uuids_col, alt_allele_freq, ref_allele_freq, minor_allele_freq, minor_allele, ref_col, ref_uuids_col, missing_col, alleles_dist_col]\n",
    "    \n",
    "    data_dict = dict(zip(out_names, out_data))\n",
    "    \n",
    "    return data_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_gencode_genes(cnv_info):\n",
    "    \n",
    "    \n",
    "    tss_bt = pbt.BedTool('/publicdata/gencode_v19_20151104/tss_merged.bed')                     \n",
    "    genes = pbt.BedTool('/publicdata/gencode_v19_20151104/genes.bed')\n",
    "    exons = pbt.BedTool('/publicdata/gencode_v19_20151104/exons.bed')\n",
    "    \n",
    "    transcript_to_gene = '/publicdata/gencode_v19_20151104/transcript_to_gene.tsv'\n",
    "    tg= pd.read_table(transcript_to_gene, index_col=0, header=None, squeeze=True)\n",
    "    \n",
    "    # need the chr prefix to intersect gencode \n",
    "    \n",
    "    cnv_info.Chr = cnv_info.Chr.astype(str)\n",
    "    cnv_info['chrom'] = cnv_info.Chr.apply(lambda x : 'chr' + x)\n",
    "    \n",
    "    cnv_info = cnv_info.sort_values(['Chr', 'Start', 'End'])\n",
    "    \n",
    "    \n",
    "    cnv_bt = pbt.BedTool.from_dataframe(cnv_info[['chrom','Start', 'End', 'ID']])\n",
    "    \n",
    "    \n",
    "    cnv_info.index = cnv_info.ID\n",
    "    \n",
    "    # Find genes that the CNV overlaps.\n",
    "    res = cnv_bt.intersect(genes, wo=True)\n",
    "    df = res.to_dataframe()\n",
    "    df['gene'] = df.thickEnd\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['overlaps_gene'] = se.apply(lambda x: set(x))\n",
    "\n",
    "    # Find genes that the CNV contains completely.\n",
    "    df = df[df.blockSizes == df.thickStart - df.strand]\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['contains_gene'] = se.apply(lambda x: set(x))  \n",
    "\n",
    "    # Annotate with genes where the CNV overlaps exonic regions.\n",
    "    res = cnv_bt.intersect(exons, wo=True)\n",
    "    df = res.to_dataframe()\n",
    "    df['gene'] = df.thickEnd.apply(lambda x: tg[x])\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['overlaps_gene_exon'] = se.apply(lambda x: set(x))    \n",
    "\n",
    "    # Distance to nearest TSS.\n",
    "    res = cnv_bt.closest(tss_bt, D='b')\n",
    "    df = res.to_dataframe()\n",
    "    cnv_info.loc[df.name, 'nearest_tss_dist'] = df.thickEnd.values\n",
    "    \n",
    "    \n",
    "    return cnv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_lambda(x,dict_in):\n",
    "    Chr = str(x.Chr)\n",
    "    Start = int(x.Start)\n",
    "    End = int(x.End)\n",
    "    \n",
    "    cent_start = dict_in[Chr][0]\n",
    "    cent_end = dict_in[Chr][1]\n",
    "    \n",
    "    ## CNV before\n",
    "    if Start < cent_start and End < cent_start:\n",
    "        dist = End - cent_start\n",
    "    ## CNV after \n",
    "    \n",
    "    elif Start > cent_end:\n",
    "        dist = Start- cent_end\n",
    "    \n",
    "    ## CNV overlaps right edge:\n",
    "    elif Start < cent_start and End > cent_start and End < cent_end:\n",
    "        dist = 0\n",
    "    ## CNV overlaps left edge\n",
    "    \n",
    "    elif Start > cent_start and Start < cent_end and End > cent_end:\n",
    "        dist=0\n",
    "    \n",
    "    ## CNV Overlaps entire region:\n",
    "    elif Start < cent_start and End > cent_end:\n",
    "        dist =0\n",
    "    ## CNV_within centromere entirely\n",
    "    elif Start > cent_start and Start < cent_end and End > cent_start and End < cent_end:\n",
    "        dist = 0\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_filters(cnv_info):\n",
    "    \n",
    "    gs_BT = pbt.BedTool.from_dataframe(cnv_info[['Chr','Start', 'End', 'ID']]).sort()\n",
    "    \n",
    "    cent_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/centromeres_merged.bed')\n",
    "    lcrs_BT = pbt.BedTool('/frazer01/home/djakubosky/software/wham/data/LCR-hs37d5.bed')\n",
    "\n",
    "    seg_dupes_BT = pbt.BedTool('/frazer01/home/djakubosky/masks/hg19.segdup.mod.bed')  \n",
    "    \n",
    "    vdj_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/vdj.bed')\n",
    "    mhc_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/mhc.bed')\n",
    "    \n",
    "    pseudo_x_bt = pbt.BedTool('X\\t60001\\t2699520', from_string=True)\n",
    "    \n",
    "    \n",
    "    centromeres = pd.read_pickle('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/centromeres.pkl')\n",
    "    cent_dict = {}\n",
    "    for x,y,z in zip(centromeres.chrom, centromeres.start, centromeres.end):\n",
    "        cent_dict[str(x)] = [int(y),int(z)]\n",
    "        \n",
    "        \n",
    "    telomeres = pd.read_pickle('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/telomeres.pkl')\n",
    "        \n",
    "    tel_start = telomeres[telomeres.ID.apply(lambda x: x.split('_')[1]=='Start')]\n",
    "    tel_end = telomeres[telomeres.ID.apply(lambda x: x.split('_')[1]=='End')]\n",
    "    tel_start_dict = {}\n",
    "    for x, y, z in zip(tel_start.Chr, tel_start.Start, tel_start.End):\n",
    "        tel_start_dict[x] = [int(y), int(z)]\n",
    "    tel_end_dict = {}\n",
    "    for x, y, z in zip(tel_end.Chr, tel_end.Start, tel_end.End):\n",
    "        tel_end_dict[x] = [int(y), int(z)] \n",
    "    \n",
    "    for label,bed in zip(['MHC', 'VDJ', 'centromere', 'seg_dupe', 'pseudo_auto'], [mhc_BT, vdj_BT, cent_BT, seg_dupes_BT, pseudo_x_bt]):\n",
    "        try:\n",
    "\n",
    "            df = gs_BT.intersect(bed, wa=True).to_dataframe()\n",
    "            cnv_info[label]=False\n",
    "            cnv_info.loc[df['name'].tolist(), label] = True\n",
    "        except:\n",
    "            cnv_info[label]=False    \n",
    "  \n",
    "    \n",
    "    \n",
    "    cnv_info['cent_dist']= cnv_info.apply(lambda x: dist_lambda(x, cent_dict), axis=1)\n",
    "    cnv_info['tel_start_dist']= cnv_info.apply(lambda x: dist_lambda(x,tel_start_dict), axis=1)\n",
    "    cnv_info['tel_end_dist']= cnv_info.apply(lambda x: dist_lambda(x,tel_end_dict), axis=1)\n",
    "    \n",
    "    return cnv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def annotate_new_cols_to_info(data_out, info_df, suffix = False):\n",
    "    cols = data_out.keys()\n",
    "    \n",
    "    if suffix != 'FALSE':\n",
    "        cols_out = [ i + '_' + suffix for i in cols]\n",
    "    else:\n",
    "        cols_out = cols\n",
    "    \n",
    "    for c_name, k in zip(cols_out, cols):\n",
    "        info_df[c_name] = data_out[k]\n",
    "    \n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_maf(info, gts, samples, sex_dict, suff):\n",
    "    \n",
    "    gt_trans = gts[samples].T\n",
    "    chrom_dict = info['#CHROM'].to_dict()\n",
    "    data_out = calculate_minor_allele_freq(gt_trans, samples, chrom_dict, sex_dict)\n",
    "    info = annotate_new_cols_to_info(data_out, info, suffix= suff)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_maf_sample_subsets(sample_lists, suffix_lists, info, gts, sex_dict):\n",
    "    \n",
    "    for samps, suff in zip(sample_lists, suffix_lists):\n",
    "        info = annotate_maf(info, gts, samps, sex_dict, suff)\n",
    "    \n",
    "    return info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Argument handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_arguments_to_parser(parser):\n",
    "    \n",
    "\n",
    "    parser.add_argument(\"-info\", \"--info\", dest=\"info\", metavar='<info>', help=\"lumpy info pickle for all variants (av)\", required=True)\n",
    "\n",
    "    \n",
    "    parser.add_argument(\"-gt\", \"--lumpy_gt\", dest=\"lumpy_gt\", metavar='<gt>', help=\"lumpy gt pickle\", required=True)\n",
    "        \n",
    "    \n",
    "    parser.add_argument(\"-caller\", \"--caller\", dest=\"caller\", metavar='<variant caller>', help=\"MELT/lumpy\", required=True)\n",
    "\n",
    "    \n",
    "    parser.add_argument(\"-gender_map\", \"--gender_map\", dest=\"gender_map\", metavar='<gender_map>', help=\"gender file UUID Sex, tab delimited\", required=True)   \n",
    "    \n",
    "    parser.add_argument(\"-intersect\", \"--intersections\", dest=\"intersect\", action = 'store_true', help=\"intersect with MHC VDJ Centromeres, Telomeres\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-s\", \"--samples\", dest=\"samples\", metavar='<fn_samples1,fn_samples2>', help=\"sets of samples to annotate\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-ss_suff\", \"--suffix_subsets\", dest=\"suffix_subsets\", metavar='<suff1,suff2,suff3>', help=\"suffixes to use for naming columns of annotated subsets of samples ex: unrelated, related\", required=True, default=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     parser.add_argument(\"-intersect\", \"--intersections\", dest=\"intersect\", metavar='<True/False>', help=\"intersect with MHC VDJ Centromeres, Telomeres\", required=False, default=True)\n",
    "    \n",
    "#     parser.add_argument(\"-somatic\", \"--somatic\", dest=\"somatic\", metavar='<Sample,region,svtype>', help=\"annotate presence of a known somatic variant, svtype indicates which variant type the somatic variant is.  useful if you know that you have a somatic variant with other evidence such as arrays from different cell types on the same individuals\", required=False, default=False)\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-genes\", \"--genes\", dest=\"genes\", action = 'store_true', help=\"annotate intersection with gencode genes\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-o\", \"--output_dir\", dest=\"output_dir\", metavar='<out_dir>', help=\"output directory for summary output\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-pre\", \"--prefix\", dest=\"prefix\", metavar='<prefix>', help=\"prefix to name files\", default = False)\n",
    "    \n",
    "    parser.add_argument(\"-suff\", \"--suffix\", dest=\"suffix\", metavar='<suffix>', help=\"prefix to name files\", default = False)\n",
    "    \n",
    "\n",
    "    parser.set_defaults(entry_point=run_from_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def command_parser():\n",
    "    parser = argparse.ArgumentParser(description= 'command line utility to annotate extracted info and genotypes from lumpy/melt with various things such as gene intersections, minor allele frequency etc.')\n",
    "    add_arguments_to_parser(parser)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_from_args(args):\n",
    "    info = pd.read_pickle(args.info)\n",
    "    gts = pd.read_pickle(args.lumpy_gt)\n",
    "    caller = args.caller\n",
    "    output_dir = args.output_dir\n",
    "    \n",
    "    # sample sets\n",
    "    samples = str(args.samples)\n",
    "    sample_files = samples.split(',')\n",
    "    \n",
    "    sample_lists = []\n",
    "    for fn in sample_files:\n",
    "        samples = [line.rstrip() for line in open(fn)]\n",
    "        sample_lists.append(samples)\n",
    "    \n",
    "    # suffixes for sample sets in info\n",
    "    suffixes = args.suffix_subsets\n",
    "    suffixes = suffixes.split(',')\n",
    "    \n",
    "    gender_file = args.gender_map\n",
    "    \n",
    "    sex_dict = {line.rstrip().split()[0]:line.rstrip().split()[1] for line in open(gender_file)}\n",
    "   \n",
    "    \n",
    "    print 'starting annotation'\n",
    "    print CM.datestring(hour=True, minute=True)\n",
    "    \n",
    "    # fix a few naming conventions fix irregularities from BND calls\n",
    "    # dtypes will be screwed up if we don't make some helper columns\n",
    "    \n",
    "    info['Chr'] = info['#CHROM'].astype(str)\n",
    "    info['Start'] = info['POS'].astype(int)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        inds = info[info.END=='Column_Not_Present'].index.tolist()\n",
    "        info.loc[inds, 'END'] = info.loc[inds, 'Start']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    info['End'] = info['END'].astype(int)\n",
    "    \n",
    "    gts = gts.loc[info.index.tolist()]\n",
    "    info = annotate_maf_sample_subsets(sample_lists, suffixes, info, gts, sex_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if args.intersect:\n",
    "        print \"annotating centromere/telomere distances, MHC, VDJ Regions\"\n",
    "        info = annotate_filters(info)\n",
    "#         print gs_info\n",
    "    \n",
    "#     if args.somatic:\n",
    "#         print \"annotating somatic variants\"\n",
    "#         spl = args.somatic.split(',')\n",
    "#         uuid = spl[0]\n",
    "#         region = spl[1]\n",
    "#         svtype = spl[2]\n",
    "#         gs_info = annotate_somatic_var(gs_info, uuid, region, svtype)\n",
    "        \n",
    "    if args.genes == True:\n",
    "        print \"annotating gencode genes\"\n",
    "        info = annotate_gencode_genes(info)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if args.suffix:\n",
    "        fn_info = os.path.join(output_dir, '{}_info'.format(caller) + args.suffix)\n",
    "        var_name_info = '{}_info'.format(caller) + args.suffix\n",
    "\n",
    "    \n",
    "    else:\n",
    "        fn_info = os.path.join(output_dir, '{}_info'.format(caller))\n",
    "        var_name_info = '{}_info'.format(caller)\n",
    "        \n",
    "    \n",
    "    \n",
    "    print 'data annotated'\n",
    "    CM.save_dataframe(var_name_info, info, output_dir, print_vars_recorded_loc=False)\n",
    "#     CM.save_dataframe(var_name_cns, gs_cns, output_location, print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = command_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    sys.exit(args.entry_point(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
