{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import djPyBio as DJ\n",
    "from djPyBio import Common as CM\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy \n",
    "import pybedtools as pbt\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "import itertools\n",
    "import tempfile\n",
    "import six\n",
    "import networkx as nx\n",
    "from scipy.stats import mode\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from mpl_toolkits.axes_grid1 import  make_axes_locatable\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import mode\n",
    "from djPyBio import Common as CM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mode_col(tran, uuids):\n",
    "    modes = []\n",
    "    nnrefs = []\n",
    "\n",
    "    for c in tran.columns:\n",
    "        l = tran[c].tolist()\n",
    "        m = int(mode(l).mode[0])\n",
    "        \n",
    "        nnref = 0\n",
    "        count = 0\n",
    "        nref_uuids = []\n",
    "        for c in l:\n",
    "            \n",
    "            if c <> m:\n",
    "                nnref +=1\n",
    "                nref_uuids.append(uuids[count])\n",
    "            count +=1\n",
    "        \n",
    "        nnrefs.append(nnref)\n",
    "        modes.append(m)\n",
    "        \n",
    "        \n",
    "    return modes, nnref, nref_uuids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_div(x, y, alt=0):\n",
    "    try:\n",
    "        return x/y\n",
    "    except:\n",
    "        return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_biallelic(l_dict, uuids_to_test, chrom, sex_dict, svtype = 'DEL'):\n",
    "    \n",
    "    if chrom not in ['X', 'Y']:\n",
    "        \n",
    "        del_dict = {0:'1/1', 1: '0/1', 2: '0/0'}\n",
    "        dup_dict = {2:'0/0', 3: '0/1' , 4: '1/1'}\n",
    "        trans_dict = {}\n",
    "        if svtype == 'DUP':\n",
    "            for s in uuids_to_test:\n",
    "                trans_dict[s] = dup_dict[int(l_dict[s])]\n",
    "        if svtype == 'DEL':\n",
    "            for s in uuids_to_test:\n",
    "                trans_dict[s] = del_dict[int(l_dict[s])]\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        conv_dict = {'DEL': {'F': {0:'1/1', 1: '0/1', 2: '1/1'}, 'M': {0:'0/1', 1: '0/0'}}, \n",
    "                    'DUP': {'F': {2:'0/0', 3: '0/1' , 4: '1/1'}, 'M':  {1:'0/0', 2: '0/1'}}}\n",
    "        \n",
    "        if chrom == 'X':\n",
    "            for s in uuids_to_test:\n",
    "                sex = sex_dict[s]\n",
    "                trans_dict[s] = conv_dict[svtype][sex][int(l_dict[s])]\n",
    "                \n",
    "        \n",
    "        if chrom == 'Y':\n",
    "            for s in uuids_to_test:\n",
    "                sex = sex_dict[s]\n",
    "                if sex == 'M':\n",
    "                    trans_dict[s] = conv_dict[svtype][sex][int(l_dict[s])]\n",
    "                else:\n",
    "                    trans_dict[s] = './.'\n",
    "                      \n",
    "    return trans_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_maf_lightweight(gts_dict, chrom, sex_dict):\n",
    "    \n",
    "    c = Counter(gts_dict.values())\n",
    "    if chrom not in ['X', 'Y']:\n",
    "    \n",
    "#         gts_dict_convert = {'0/0':0, '0/1':1, '1/1':2, './.':0}\n",
    "\n",
    "        ref_allele = (c.get('0/0', 0) * 2) + (c.get('0/1', 0) * 1)\n",
    "        alt_allele = (c.get('0/1', 0) * 1) + (c.get('1/1', 0) * 2) \n",
    "        tot_alleles = ref_allele + alt_allele\n",
    "\n",
    "#         ref_af = safe_div(ref_allele, tot_alleles, alt='All Missing')\n",
    "#         alt_af = safe_div(alt_allele, tot_alleles, alt='All Missing')\n",
    "#         afs = [ref_af, alt_af]\n",
    "\n",
    "            \n",
    "    else:\n",
    "        male_gts = [gts_dict[s] for s in gts_dict.keys() if sex_dict[s] == 'M']\n",
    "        female_gts =  [gts_dict[s] for s in gts_dict.keys() if sex_dict[s] == 'F']\n",
    "    \n",
    "        c_male = Counter(male_gts)\n",
    "        c_female = Counter(female_gts)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ref_allele_f = (c_female.get('0/0', 0) * 2) + (c_female.get('0/1', 0) * 1) \n",
    "        alt_allele_f = (c_female.get('0/1', 0) * 1) + (c_female.get('1/1', 0) * 2) \n",
    "        \n",
    "        ref_allele_m = (c_male.get('0/0', 0) * 1) + (c_male.get('0/1', 0) * 1) \n",
    "        alt_allele_m = (c_male.get('0/1', 0) * 1)\n",
    "        \n",
    "        ref_allele = ref_allele_f + ref_allele_m \n",
    "        alt_allele = alt_allele_f + alt_allele_m \n",
    "        \n",
    "        tot_alleles = ref_allele + alt_allele\n",
    "    \n",
    "    \n",
    "    ref_af = safe_div(ref_allele, tot_alleles, alt='All Missing')\n",
    "    alt_af = safe_div(alt_allele, tot_alleles, alt='All Missing')\n",
    "    afs = [ref_af, alt_af]\n",
    "\n",
    "\n",
    "    maf = 0.0\n",
    "    minor_allele = 'ALT'\n",
    "    if not tot_alleles == 0:\n",
    "        maf = min(afs)\n",
    "        if afs.index(maf) == 0:\n",
    "            minor_allele = 'REF'\n",
    "        else:\n",
    "            minor_allele = 'ALT'\n",
    "\n",
    "\n",
    "    if minor_allele == 'ALT':\n",
    "        non_ref = c.get('0/1', 0) + c.get('1/1', 0)\n",
    "        ref = c.get('0/0', 0)\n",
    "    if minor_allele == 'REF':\n",
    "        non_ref = c.get('0/1', 0) + c.get('0/0', 0)\n",
    "        ref = c.get('1/1', 0)      \n",
    "        \n",
    "    out_names = ['NNREF', 'ALTAF', 'REFAF', 'MAF', 'Minor_Allele', 'NREF']\n",
    "    out_data = [non_ref, alt_af, ref_af, maf, minor_allele, ref]\n",
    "    data_dict = dict(zip(out_names, out_data))\n",
    "    \n",
    "    return out_data, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_variant_class(min_allele, max_allele, ref):\n",
    "    \n",
    "    if min_allele == max_allele:\n",
    "        return \"Non_Bi\"\n",
    "    \n",
    "    if (min_allele < ref) and (max_allele > ref):\n",
    "        return 'MIXED'\n",
    "    \n",
    "    if (max_allele > ref) and (min_allele ==ref):\n",
    "        return 'DUP'\n",
    "    if (min_allele < ref) and( max_allele == ref):\n",
    "        return 'DEL'\n",
    "    \n",
    "    if (min_allele > ref) and (max_allele > ref) and (min_allele != max_allele):\n",
    "        \n",
    "        return 'DUP'\n",
    "    \n",
    "    if (min_allele < ref) and (max_allele < ref):\n",
    "        return 'DEL'\n",
    "\n",
    "\n",
    "def minimum_predicted_alleles(min_in, max_in, diploid = True):\n",
    "    \"\"\"compute minimum predicted haploid \n",
    "    alleles that can explain a range of CN between the min and max diploid CN \n",
    "    that could exist in a population \"\"\"\n",
    "    \n",
    "    if diploid == True:\n",
    "        \n",
    "        if min_in==max_in:\n",
    "            num_alleles_predicted = 1\n",
    "\n",
    "        elif min_in >= 1:\n",
    "            num_alleles_predicted = 1 + round(max_in/2) - round((min_in-1)/2)\n",
    "\n",
    "        else:\n",
    "            num_alleles_predicted = round(max_in/2) - round((min_in-1)/2)\n",
    "            \n",
    "    else:\n",
    "        # if a haploid situation, assume we have all the individual alleles in the range\n",
    "        if min_in==max_in:\n",
    "            num_alleles_predicted = 1\n",
    "        else:\n",
    "            num_alleles_predicted = (max_in - min_in) + 1\n",
    "    \n",
    "    return num_alleles_predicted\n",
    "\n",
    "\n",
    "def get_variant_type_info(min_allele, max_allele, min_allele_males, max_allele_males, min_allele_females, \n",
    "             max_allele_females, chrom):\n",
    "    \n",
    "    ref = 2\n",
    "    ref_males = 1\n",
    "    \n",
    "    if chrom =='Y':\n",
    "        variant_class = estimate_variant_class(min_allele_males, max_allele_males, ref_males)\n",
    "        min_pred_alleles= minimum_predicted_alleles(min_allele_males, max_allele_males, diploid= False)\n",
    "        \n",
    "    elif chrom == 'X':\n",
    "        variant_class_males = estimate_variant_class(min_allele_males, max_allele_males, ref_males)\n",
    "        variant_class_females = estimate_variant_class(min_allele_females, max_allele_females, ref)\n",
    "        \n",
    "        min_pred_alleles_males = minimum_predicted_alleles(min_allele_males, max_allele_males, diploid= False)\n",
    "        min_pred_alleles_females = minimum_predicted_alleles(min_allele_females, max_allele_males)\n",
    "        \n",
    "        min_pred_alleles = max(min_pred_alleles_males, min_pred_alleles_females)\n",
    "        \n",
    "        vts = set([variant_class_males, variant_class_females])\n",
    "        if len(vts) > 1:\n",
    "            MIXED= set(['DUP', 'DEL'])\n",
    "            if 'MIXED' in vts:\n",
    "                variant_class = 'MIXED'\n",
    "            elif vts == MIXED:\n",
    "                variant_class ='MIXED'\n",
    "            \n",
    "            else:\n",
    "                vts.remove('Non_Bi')\n",
    "                variant_class = vts.pop()\n",
    "            \n",
    "        else:\n",
    "            variant_class = vts.pop()\n",
    "       \n",
    "    else:\n",
    "        variant_class = estimate_variant_class(min_allele, max_allele, ref)\n",
    "        min_pred_alleles = minimum_predicted_alleles(min_allele, max_allele)\n",
    "    \n",
    "    \n",
    "    cnv_class = copy.deepcopy(variant_class)\n",
    "    \n",
    "    if (min_pred_alleles >= 3):\n",
    "        cnv_class = 'mCNV'\n",
    "    if variant_class == 'MIXED':\n",
    "        cnv_class = 'mCNV'\n",
    "    \n",
    "    \n",
    "    \n",
    "    return variant_class, cnv_class, min_pred_alleles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_biallelic_status(unique_gts_site, unique_gts_males, unique_gts_females, cnv_class, chrom):\n",
    "    if chrom not in ['X', 'Y']:\n",
    "        bi_class = is_biallelic_DUP_DEL_auto(unique_gts_site, cnv_class)\n",
    "    else:\n",
    "        bi_class = is_biallelic_DUP_DEL_xy(unique_gts_males, unique_gts_females, chrom)\n",
    "        \n",
    "    return bi_class\n",
    "\n",
    "def is_biallelic_DUP_DEL_xy(unique_gts_males, unique_gts_females, chrom):\n",
    "    \n",
    "    m_svtype = 'UNKNOWN'\n",
    "    f_svtype = 'UNKNOWN'\n",
    "\n",
    "    DUP_alleles_F = [2,3,4]\n",
    "    DEL_alleles_F = [0,1,2]\n",
    "    num_unique_F = len(unique_gts_females)\n",
    "\n",
    "    DUP_alleles_M = [1, 2]\n",
    "    DEL_alleles_M = [0,1]\n",
    "    num_unique_M = len(unique_gts_males)\n",
    "\n",
    "\n",
    "    # is it biallelic in M/F\n",
    "    if num_unique_M > 2:\n",
    "        m_svtype = 'mCNV'\n",
    "\n",
    "    elif num_unique_F > 3:\n",
    "        f_svtype = 'mCNV'\n",
    "\n",
    "    intersect_M_dup  = set(unique_gts_males).intersection(DUP_alleles_M)\n",
    "    intersect_M_del  = set(unique_gts_males).intersection(DEL_alleles_M)\n",
    "\n",
    "\n",
    "    intersect_F_dup  = set(unique_gts_females).intersection(DUP_alleles_F)\n",
    "    intersect_F_del  = set(unique_gts_females).intersection(DEL_alleles_F)\n",
    "    \n",
    "    if chrom == 'X':\n",
    "\n",
    "        if len(intersect_M_dup) == num_unique_M:\n",
    "            m_svtype == 'DUP'\n",
    "\n",
    "        if len(intersect_M_del) == num_unique_M:\n",
    "            m_svtype == 'DEL'\n",
    "\n",
    "        if len(intersect_F_dup) == num_unique_F:\n",
    "            f_svtype == 'DUP'\n",
    "\n",
    "        if len(intersect_F_del) == num_unique_F:\n",
    "            f_svtype == 'DEL'\n",
    "\n",
    "        if f_svtype == m_svtype:\n",
    "            return f_svtype\n",
    "\n",
    "        else:\n",
    "            return 'UNKNOWN'\n",
    "        \n",
    "    if chrom == 'Y':\n",
    "        \n",
    "        if len(intersect_M_dup) == num_unique_M:\n",
    "            m_svtype == 'DUP'\n",
    "            \n",
    "        if len(intersect_M_del) == num_unique_M:\n",
    "            m_svtype == 'DEL'\n",
    "        \n",
    "        return m_svtype\n",
    "\n",
    "def is_biallelic_DUP_DEL_auto(unique_gts_site, cnv_class):\n",
    "    \"\"\" for autosomes \"\"\"\n",
    "    DUP_alleles = [2,3,4]\n",
    "    DEL_alleles = [0,1,2]\n",
    "    num_unique = len(unique_gts_site)\n",
    "    \n",
    "    \n",
    "    if num_unique > 3:\n",
    "        return cnv_class\n",
    "    \n",
    "    if cnv_class == 'DUP':\n",
    "        intersect = set(unique_gts_site).intersection(DUP_alleles)\n",
    "        if len(intersect) == num_unique:\n",
    "            return 'DUP'\n",
    "    \n",
    "    elif cnv_class == 'DEL':\n",
    "        intersect = set(unique_gts_site).intersection(DEL_alleles)\n",
    "        if len(intersect) == num_unique:\n",
    "            return 'DEL'  \n",
    "    else:\n",
    "        return cnv_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_annotations(tran, uuids, sex_dict, lq_dict = False):\n",
    "    \n",
    "    modes_col = []\n",
    "    modes_male_col = []\n",
    "    modes_female_col = []\n",
    "    nnrefs_col = []\n",
    "    unique_gts_col = []\n",
    "    alleles_dist_col = []\n",
    "    alleles_dist_males_col = []\n",
    "    alleles_dist_females_col = []\n",
    "    \n",
    "    \n",
    "    variants_discovered_col = []\n",
    "    variant_allele_count_col = []\n",
    "    count_alleles_col = []\n",
    "    min_allele_col = []\n",
    "    max_allele_col = []\n",
    "    \n",
    "    min_allele_males_col = []\n",
    "    max_allele_males_col = []\n",
    "    \n",
    "    min_allele_females_col = []\n",
    "    max_allele_females_col = []\n",
    "    \n",
    "    is_mixed_col = []\n",
    "    percent_diff_from_mode_col = []\n",
    "    \n",
    "    nref_uuids_col = []\n",
    "    \n",
    "    min_alleles_pred_col = []\n",
    "    cnv_class_col = []\n",
    "    cnv_subclass_col = []\n",
    "    lq_ind_col = []\n",
    "    all_lq_col = []\n",
    "    lq_samps_col = []\n",
    "    num_lq_col = []\n",
    "    num_non_lq_col = []\n",
    "    non_lq_samps_col  = []\n",
    "    bi_class_col = []\n",
    "    non_ref_af_col = []\n",
    "    \n",
    "    unique_gts_males_col = []\n",
    "    unique_gts_females_col = []\n",
    "    \n",
    "    maf_data = []\n",
    "    \n",
    "    maf_col = []\n",
    "    minor_allele_col = []\n",
    "    \n",
    "    try:\n",
    "        males = [i for i in uuids if sex_dict[i]=='M']\n",
    "    except:\n",
    "        males = []\n",
    "    \n",
    "    try:\n",
    "        females = [i for i in uuids if sex_dict[i]=='F']\n",
    "    except:\n",
    "        females = []\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    for c in tran.columns:\n",
    "        chrom = c.split('_')[1]\n",
    "        \n",
    "        try:\n",
    "            l = tran[c].tolist()\n",
    "            l_dict = tran[c].to_dict()\n",
    "            \n",
    "        except:\n",
    "            print c\n",
    "            \n",
    "        \n",
    "        lq_inds = []\n",
    "        lq_samps = []\n",
    "        if lq_dict:\n",
    "            lq = lq_dict[c]\n",
    "            if lq:\n",
    "                # filter to those in the current sample subset\n",
    "                lq_samps = [i for i in lq if i in uuids]\n",
    "\n",
    "                if len(lq_samps) > 0:\n",
    "                    uuids_to_test = set(uuids).difference(lq_samps)\n",
    "                    \n",
    "                else:\n",
    "                    uuids_to_test = copy.deepcopy(uuids)\n",
    "\n",
    "            else:\n",
    "                uuids_to_test = copy.deepcopy(uuids)\n",
    "        else:\n",
    "            uuids_to_test = copy.deepcopy(uuids)\n",
    "        \n",
    "        l_all = [l_dict[s] for s in uuids]\n",
    "        l_males_all = [l_dict[s] for s in males]\n",
    "        l_females_all = [l_dict[s] for s in females]\n",
    "       \n",
    "        l_filt = [l_dict[s] for s in uuids_to_test]\n",
    "        \n",
    "      \n",
    "        non_lq_samps_col.append(uuids_to_test)\n",
    "        lq_samps_col.append(lq_samps)\n",
    "        \n",
    "        lq_len = len(lq_samps)\n",
    "        num_lq_col.append(lq_len)\n",
    "        \n",
    "        num_pass = len(l_filt)\n",
    "        num_non_lq_col.append(num_pass)\n",
    "          \n",
    "        # check if all are filtered- to continue processing- \n",
    "        # we will continue instead as if they aren't LQ, and adjust later using the all_lq column\n",
    "        \n",
    "        all_lq = False\n",
    "        if len(l_filt) == 0:\n",
    "            all_lq = True\n",
    "            m = int(mode(l_all).mode[0])\n",
    "        else:\n",
    "            try:\n",
    "                m = int(mode(l_filt).mode[0])\n",
    "            except:\n",
    "                print 'THIS', l_all, c\n",
    "                break\n",
    "    \n",
    "        # sex specific modes      \n",
    "        no_males = False\n",
    "        no_females = False\n",
    "        \n",
    "        male_gts_filt = copy.deepcopy(l_males_all)\n",
    "        if len(l_males_all) > 0:\n",
    "            males_filt = list(set(males).intersection(uuids_to_test))\n",
    "            if len(males_filt) > 0:\n",
    "                male_gts_filt = [l_dict[i] for i in males if i in uuids_to_test]\n",
    "                num_passing_males = len(male_gts_filt)\n",
    "                mode_males = int(mode(male_gts_filt).mode[0])\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                mode_males = int(mode(l_males_all).mode[0])\n",
    "                num_passing_males = 0\n",
    "                no_males = True\n",
    "        else:\n",
    "            num_passing_males = 0\n",
    "            no_males = True\n",
    "        \n",
    "        female_gts_filt = copy.deepcopy(l_females_all)\n",
    "        if len(l_females_all) > 0:\n",
    "            females_filt = list(set(females).intersection(uuids_to_test))\n",
    "            if len(females_filt) > 0:\n",
    "                female_gts_filt = [l_dict[i] for i in females if i in uuids_to_test]\n",
    "                num_passing_females = len(female_gts_filt)\n",
    "                mode_females = int(mode(female_gts_filt).mode[0])\n",
    "                \n",
    "            else:\n",
    "                no_females = True\n",
    "                num_passing_females = 0\n",
    "                mode_females = int(mode(l_females_all).mode[0])\n",
    "                \n",
    "        else:\n",
    "            num_passing_females = 0\n",
    "            no_females = True\n",
    "        \n",
    "        \n",
    "        nnref = 0\n",
    "        nnmode = 0\n",
    "        count = 0\n",
    "        nref_uuids = []\n",
    "        alleles_dist = {}\n",
    "        unique_nref_vars = []\n",
    "        unique_non_mode_vars = []\n",
    "        alleles_discovered = []\n",
    "        \n",
    "        alleles_males = []\n",
    "        alleles_females = []\n",
    "        \n",
    "        #iterate through gts at each site\n",
    "#         l = map(int, l) \n",
    "\n",
    "        s_to_test = set(uuids_to_test)\n",
    "        \n",
    "        all_vars = []\n",
    "        for s in uuids:\n",
    "            t = int(l_dict[s])\n",
    "            \n",
    "            if not all_lq:\n",
    "                if s not in s_to_test:\n",
    "                    continue\n",
    "                    \n",
    "            \n",
    "            all_vars.append(t)\n",
    "            sex = sex_dict[s]\n",
    "            \n",
    "            \n",
    "            if sex == 'M':\n",
    "                alleles_males.append(t)\n",
    "            elif sex == 'F':\n",
    "                alleles_females.append(t)\n",
    "            \n",
    "            # sex chroms\n",
    "            if chrom == 'Y':\n",
    "                if sex == 'M':\n",
    "                    \n",
    "                    alleles_discovered.append(t)\n",
    "                    # record alleles only of males for y chrom\n",
    "                    alleles_dist[t] = alleles_dist.get(t, 0) + 1\n",
    "\n",
    "\n",
    "                    if t <> 1:\n",
    "                        nnref += 1\n",
    "                        unique_nref_vars.append(t)\n",
    "\n",
    "                    if t <> mode_males:\n",
    "                        nnmode +=1\n",
    "                        unique_non_mode_vars.append(t)\n",
    "                        nref_uuids.append(s)\n",
    "            \n",
    "            elif chrom == 'X':\n",
    "                alleles_discovered.append(t)\n",
    "                alleles_dist[t] = alleles_dist.get(t, 0) +1\n",
    "                if sex == 'M':\n",
    "                    \n",
    "                    if t <> 1:\n",
    "                        nnref += 1\n",
    "                        unique_nref_vars.append(t)  \n",
    "                    if t <> mode_males:\n",
    "                        nnmode +=1\n",
    "                        unique_non_mode_vars.append(t)\n",
    "                        nref_uuids.append(s)\n",
    "                else:\n",
    "                        \n",
    "                    if t <> 2:\n",
    "                        nnref +=1\n",
    "                        unique_nref_vars.append(t)\n",
    "                    \n",
    "                    if t <> mode_females:\n",
    "                        nnmode +=1\n",
    "                        unique_non_mode_vars.append(t)\n",
    "                        nref_uuids.append(s)\n",
    "            # autosomes      \n",
    "            else:\n",
    "                alleles_discovered.append(t)\n",
    "                alleles_dist[t] = alleles_dist.get(t, 0) +1\n",
    "                # lets also record vars that deviate from 2\n",
    "                if t <> 2:\n",
    "                    nnref += 1\n",
    "                    unique_nref_vars.append(t)\n",
    "                        \n",
    "                # vars that deviate from the mode \n",
    "                if t <> m:\n",
    "                    nnmode +=1\n",
    "                    unique_non_mode_vars.append(t)\n",
    "                    nref_uuids.append(s)\n",
    "            \n",
    "            \n",
    "            count +=1\n",
    "        \n",
    "        alleles_dist_col.append(alleles_dist)\n",
    "        alleles_dist_males_col.append(dict(Counter(alleles_males)))\n",
    "        alleles_dist_females_col.append(dict(Counter(alleles_females)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # set of variants that deviates from expected diploid CN of reference (2 copies or 1 copy on male sex chroms)\n",
    "        vars_at_site = list(set(unique_non_mode_vars))\n",
    "        variants_discovered_col.append(vars_at_site)\n",
    "       \n",
    "    \n",
    "        # number of different alleles taht deviate from expected diploid cn (not MODE cn)\n",
    "        variant_allele_count_col.append(len(vars_at_site))\n",
    "        \n",
    "        count_alleles_col.append(len(alleles_dist))\n",
    "        \n",
    "        nnrefs_col.append(nnref)\n",
    "        all_lq_col.append(all_lq)\n",
    "        # calculate percent diff from mode CN - do this separately for x and y chroms\n",
    "        if chrom == 'Y':\n",
    "            percent_diff_from_mode = nnmode/(len(male_gts_filt))\n",
    "            nonref_af = nnref/(len(male_gts_filt))\n",
    "            \n",
    "        else:\n",
    "        \n",
    "            if all_lq:\n",
    "                num_pass = len(l_all)                \n",
    "                \n",
    "            else:\n",
    "                num_pass = len(l_filt)\n",
    "            \n",
    "            percent_diff_from_mode = nnmode/num_pass\n",
    "            nonref_af = nnref/num_pass\n",
    "        \n",
    "        percent_diff_from_mode_col.append(percent_diff_from_mode)\n",
    "        non_ref_af_col.append(nonref_af)\n",
    "        # col of uuids that are diff from mode\n",
    "        \n",
    "        nref_uuids_col.append(nref_uuids)\n",
    "        modes_col.append(m)\n",
    "        modes_male_col.append(mode_males)\n",
    "        modes_female_col.append(mode_females)\n",
    "        \n",
    "        \n",
    "        # col of unique genotypes at the site (all copy numbers)\n",
    "        unique_gts_site = list(set(alleles_discovered))\n",
    "        unique_gts_males = list(set(alleles_males))\n",
    "        unique_gts_females = list(set(alleles_females))\n",
    "        \n",
    "         \n",
    "        min_allele = min(unique_gts_site)\n",
    "        max_allele  = max(unique_gts_site)\n",
    "        \n",
    "        \n",
    "        gt_list = [unique_gts_males, unique_gts_females]\n",
    "        min_max = []\n",
    "        \n",
    "        for g in gt_list:\n",
    "            try:\n",
    "                min_a = min(g)\n",
    "            except:\n",
    "                min_a = False\n",
    "            try:\n",
    "                max_a = max(g)\n",
    "            except:\n",
    "                max_a = False\n",
    "            \n",
    "            min_max.append([min_a, max_a])\n",
    "            \n",
    "        min_allele_males, max_allele_males = min_max[0]\n",
    "        min_allele_females, max_allele_females = min_max[1]\n",
    "          \n",
    "        \n",
    "#         min_allele_females = min(unique_gts_females)\n",
    "#         max_allele_females = max(unique_gts_females)\n",
    "        \n",
    "        unique_gts_col.append(unique_gts_site)\n",
    "        unique_gts_males_col.append(unique_gts_males)\n",
    "        unique_gts_females_col.append(unique_gts_females)\n",
    "        \n",
    "      \n",
    "        min_allele_col.append(min_allele)\n",
    "        max_allele_col.append(max_allele)\n",
    "        \n",
    "        min_allele_males_col.append(min_allele_males)\n",
    "        max_allele_males_col.append(max_allele_males)\n",
    "        \n",
    "        min_allele_females_col.append(min_allele_females)\n",
    "        max_allele_females_col.append(max_allele_females)\n",
    "        \n",
    "        variant_class, cnv_class, min_pred_alleles = get_variant_type_info(min_allele, max_allele,\n",
    "                                                                           min_allele_males,\n",
    "                                                                       max_allele_males, min_allele_females, \n",
    "                                                                       max_allele_females, chrom)\n",
    "\n",
    "        min_alleles_pred_col.append(min_pred_alleles)\n",
    "        is_mixed_col.append(variant_class)\n",
    "    \n",
    "        \n",
    "        cnv_subclass = variant_class + '_' + cnv_class\n",
    "        cnv_subclass_col.append(cnv_subclass)\n",
    "        \n",
    "        # this will mark some sex chrom things as UNKNOWN we will revisit them\n",
    "        bi_class = check_biallelic_status(unique_gts_site, unique_gts_males, \n",
    "                                                   unique_gts_females, cnv_class, chrom)\n",
    "        bi_class_col.append(bi_class)\n",
    "        \n",
    "        maf = percent_diff_from_mode\n",
    "        minor_allele = 'NA'\n",
    "        if bi_class in ['DUP', 'DEL']:\n",
    "            gt_dict = transform_to_biallelic(l_dict, uuids_to_test, chrom, sex_dict, \n",
    "                                             svtype = cnv_class)\n",
    "\n",
    "            out_data, data_dict = compute_maf_lightweight(gt_dict, chrom, sex_dict)\n",
    "            maf = data_dict['MAF']\n",
    "            minor_allele = data_dict['Minor_Allele']\n",
    "            \n",
    "            out_data = out_data + [c, cnv_class]\n",
    "            maf_data.append(out_data)\n",
    "            \n",
    "        maf_col.append(maf)\n",
    "        minor_allele_col.append(minor_allele)\n",
    "        \n",
    "        cnv_class_col.append(cnv_class)\n",
    "        \n",
    "        \n",
    "        \n",
    "    out_cols = ['ID','cn_mode', 'diff_from_mode', 'percent_diff_from_mode', 'diploid_alleles',\n",
    "                'diploid_alleles_males', 'diploid_alleles_females', \n",
    "                'count_alleles', \n",
    "               'alleles_dist', 'alleles_dist_males', 'alleles_dist_females',\n",
    "                'variant_alleles', 'variant_allele_count', \n",
    "                'min_allele', 'max_allele', 'min_allele_males', 'max_allele_males', 'min_allele_females', 'max_allele_females', 'cnv_type','min_predicted_alleles', 'cnv_class', 'cnv_subclass', 'diff_mode_uuids', 'cn_mode_male', 'cn_mode_female', 'lq_samps', 'num_lq', 'num_pass', 'all_lq', 'pass_samps', 'num_pass_males', 'num_pass_females', 'bi_class', 'MAF', 'NONREF_AF']\n",
    "    \n",
    "    \n",
    "    \n",
    "    data_array = [tran.columns.tolist(), modes_col, nnrefs_col, percent_diff_from_mode_col, unique_gts_col,\n",
    "                  unique_gts_males_col, unique_gts_females_col,\n",
    "                  count_alleles_col,\n",
    "                  alleles_dist_col, alleles_dist_males_col, alleles_dist_females_col,\n",
    "                  variants_discovered_col, variant_allele_count_col,\n",
    "                  min_allele_col,max_allele_col, min_allele_males_col, max_allele_males_col,\n",
    "                  min_allele_females_col, max_allele_females_col,\n",
    "                  is_mixed_col, min_alleles_pred_col,\n",
    "                  cnv_class_col, cnv_subclass_col, nref_uuids_col, modes_male_col, modes_female_col, \n",
    "                  lq_samps_col, num_lq_col, num_non_lq_col, all_lq_col,  non_lq_samps_col, num_passing_males,\n",
    "                  num_passing_females, bi_class_col, maf_col, non_ref_af_col]\n",
    "    # return the result as a dict of lists (this can be directly dataframe converted or added as cols individually\n",
    "\n",
    "        \n",
    "    return  dict(zip(out_cols, data_array)), maf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geno_all_with_stitch = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/gs_processing_V3/i2QTL_combined/cns_all_with_stitch.pkl')\n",
    "\n",
    "sample_info = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/sample_info_combined/sample_info.pkl')\n",
    "\n",
    "# subsets we will need for unifying genotype fields\n",
    "\n",
    "samples_ipscore = sample_info[(sample_info.STUDY == 'iPSCORE')].WGS_ID.tolist()\n",
    "\n",
    "samples_hipsci_fib = sample_info[(sample_info.STUDY == 'HipSci') & (sample_info.CELL_TYPE == 'Fibroblast')].WGS_ID.tolist()\n",
    "\n",
    "info = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/gs_processing_V3/i2QTL_combined/gs_info_stitch_annot_final.pkl')\n",
    "\n",
    "lq_dict = info.LQ_samps.to_dict()\n",
    "\n",
    "sex_dict = sample_info.SEX.to_dict()\n",
    "\n",
    "geno_all_with_stitch = geno_all_with_stitch.reindex(info.index)\n",
    "\n",
    "tran = geno_all_with_stitch[samples_ipscore].T\n",
    "\n",
    "t,t2 = gs_annotations(tran, samples_ipscore, sex_dict, lq_dict=lq_dict)\n",
    "\n",
    "cols = ['NNREF', 'ALTAF', 'REFAF', 'MAF', 'Minor_Allele', 'NREF', 'ID', 'cnv_class']\n",
    "maf_df = pd.DataFrame(t2, columns=cols)\n",
    "\n",
    "maf_df = maf_df.set_index('ID')\n",
    "\n",
    "cols = ['ID','cn_mode', 'diff_from_mode', 'percent_diff_from_mode', 'diploid_alleles',\n",
    "                'diploid_alleles_males', 'diploid_alleles_females', \n",
    "                'count_alleles', \n",
    "               'alleles_dist', 'variant_alleles', 'variant_allele_count', \n",
    "                'min_allele', 'max_allele', 'min_allele_males', 'max_allele_males', 'min_allele_females', 'max_allele_females', 'cnv_type','min_predicted_alleles', 'cnv_class', 'cnv_subclass', 'diff_mode_uuids', 'cn_mode_male', 'cn_mode_female', 'lq_samps', 'num_lq', 'num_pass', 'all_lq', 'pass_samps', 'num_pass_males', 'num_pass_females', 'bi_class']\n",
    "\n",
    "tdf = pd.DataFrame.from_dict(t)\n",
    "\n",
    "tdf = tdf.set_index(\"ID\", drop = False)\n",
    "tdf = tdf[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_gencode_genes(cnv_info):\n",
    "    \n",
    "    \n",
    "    tss_bt = pbt.BedTool('/publicdata/gencode_v19_20151104/tss_merged.bed')                     \n",
    "    genes = pbt.BedTool('/publicdata/gencode_v19_20151104/genes.bed')\n",
    "    exons = pbt.BedTool('/publicdata/gencode_v19_20151104/exons.bed')\n",
    "    \n",
    "    transcript_to_gene = '/publicdata/gencode_v19_20151104/transcript_to_gene.tsv'\n",
    "    tg= pd.read_table(transcript_to_gene, index_col=0, header=None, squeeze=True)\n",
    "    \n",
    "    # need the chr prefix to intersect gencode \n",
    "    \n",
    "    cnv_info.Chr = cnv_info.Chr.astype(str)\n",
    "    cnv_info['chrom'] = cnv_info.Chr.apply(lambda x : 'chr' + x)\n",
    "    \n",
    "    \n",
    "    cnv_bt = pbt.BedTool.from_dataframe(cnv_info[['chrom','Start', 'End', 'ID']]).sort()\n",
    "    \n",
    "    cnv_info.index = cnv_info.ID\n",
    "    cnv_info.index.name = 'index'\n",
    "    \n",
    "    # Find genes that the CNV overlaps.\n",
    "    res = cnv_bt.intersect(genes, sorted=True, wo=True)\n",
    "    df = res.to_dataframe()\n",
    "    df['gene'] = df.thickEnd\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['overlaps_gene'] = se.apply(lambda x: set(x))\n",
    "\n",
    "    # Find genes that the CNV contains completely.\n",
    "    df = df[df.blockSizes == df.thickStart - df.strand]\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['contains_gene'] = se.apply(lambda x: set(x))  \n",
    "\n",
    "    # Annotate with genes where the CNV overlaps exonic regions.\n",
    "    res = cnv_bt.intersect(exons, sorted=True, wo=True)\n",
    "    df = res.to_dataframe()\n",
    "    df['gene'] = df.thickEnd.apply(lambda x: tg[x])\n",
    "    gb = df[['name', 'gene']].groupby('name')\n",
    "    se = pd.Series(dict(list(gb['gene'])))\n",
    "    cnv_info['overlaps_gene_exon'] = se.apply(lambda x: set(x))    \n",
    "\n",
    "    # Distance to nearest TSS.\n",
    "    res = cnv_bt.closest(tss_bt, D='b')\n",
    "    df = res.to_dataframe()\n",
    "    cnv_info.loc[df.name, 'nearest_tss_dist'] = df.thickEnd.values\n",
    "    \n",
    "    \n",
    "    return cnv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist_lambda(x,dict_in):\n",
    "    Chr = str(x.Chr)\n",
    "    Start = int(x.Start)\n",
    "    End = int(x.End)\n",
    "    \n",
    "    cent_start = dict_in[Chr][0]\n",
    "    cent_end = dict_in[Chr][1]\n",
    "    \n",
    "    ## CNV before\n",
    "    if Start < cent_start and End < cent_start:\n",
    "        dist = End - cent_start\n",
    "    ## CNV after \n",
    "    \n",
    "    elif Start > cent_end:\n",
    "        dist = Start- cent_end\n",
    "    \n",
    "    ## CNV overlaps right edge:\n",
    "    elif Start < cent_start and End > cent_start and End < cent_end:\n",
    "        dist = 0\n",
    "    ## CNV overlaps left edge\n",
    "    \n",
    "    elif Start > cent_start and Start < cent_end and End > cent_end:\n",
    "        dist=0\n",
    "    \n",
    "    ## CNV Overlaps entire region:\n",
    "    elif Start < cent_start and End > cent_end:\n",
    "        dist =0\n",
    "    ## CNV_within centromere entirely\n",
    "    elif Start > cent_start and Start < cent_end and End > cent_start and End < cent_end:\n",
    "        dist = 0\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_filters(cnv_info):\n",
    "    \n",
    "    gs_BT = pbt.BedTool.from_dataframe(cnv_info[['Chr','Start', 'End', 'ID']]).sort()\n",
    "    \n",
    "    cent_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/centromeres_merged.bed')\n",
    "    lcrs_BT = pbt.BedTool('/frazer01/home/djakubosky/software/wham/data/LCR-hs37d5.bed')\n",
    "\n",
    "    seg_dupes_BT = pbt.BedTool('/frazer01/home/djakubosky/masks/hg19.segdup.mod.bed')  \n",
    "    \n",
    "    vdj_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/vdj.bed')\n",
    "    mhc_BT = pbt.BedTool('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/mhc.bed')\n",
    "    \n",
    "    pseudo_x_bt = pbt.BedTool('X\\t60001\\t2699520', from_string=True)\n",
    "    \n",
    "    \n",
    "    centromeres = pd.read_pickle('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/centromeres.pkl')\n",
    "    cent_dict = {}\n",
    "    for x,y,z in zip(centromeres.chrom, centromeres.start, centromeres.end):\n",
    "        cent_dict[str(x)] = [int(y),int(z)]\n",
    "        \n",
    "        \n",
    "    telomeres = pd.read_pickle('/frazer01/projects/CARDIPS/analysis/cardips-cnv-analysis/output/publicdata/telomeres.pkl')\n",
    "        \n",
    "    tel_start = telomeres[telomeres.ID.apply(lambda x: x.split('_')[1]=='Start')]\n",
    "    tel_end = telomeres[telomeres.ID.apply(lambda x: x.split('_')[1]=='End')]\n",
    "    tel_start_dict = {}\n",
    "    for x, y, z in zip(tel_start.Chr, tel_start.Start, tel_start.End):\n",
    "        tel_start_dict[x] = [int(y), int(z)]\n",
    "    tel_end_dict = {}\n",
    "    for x, y, z in zip(tel_end.Chr, tel_end.Start, tel_end.End):\n",
    "        tel_end_dict[x] = [int(y), int(z)] \n",
    "    \n",
    "    for label,bed in zip(['MHC', 'VDJ', 'centromere', 'seg_dupe', 'pseudo_auto'], [mhc_BT, vdj_BT, cent_BT, seg_dupes_BT, pseudo_x_bt]):\n",
    "        try:\n",
    "\n",
    "            df = gs_BT.intersect(bed, wa=True).to_dataframe()\n",
    "            cnv_info[label]=False\n",
    "            cnv_info.loc[df['name'].tolist(), label] = True\n",
    "        except:\n",
    "            cnv_info[label]=False    \n",
    "  \n",
    "    \n",
    "    \n",
    "    cnv_info['cent_dist']= cnv_info.apply(lambda x: dist_lambda(x, cent_dict), axis=1)\n",
    "    cnv_info['tel_start_dist']= cnv_info.apply(lambda x: dist_lambda(x,tel_start_dict), axis=1)\n",
    "    cnv_info['tel_end_dist']= cnv_info.apply(lambda x: dist_lambda(x,tel_end_dict), axis=1)\n",
    "    \n",
    "    return cnv_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_somatic_var(cnv_info, UUID, position, svtype):\n",
    "    \n",
    "    cnv_info['diff_from_mode_uuids_str'] = cnv_info.diff_mode_uuids.apply(lambda x: \",\".join(x))\n",
    "    chrom = position.split(':')[0]\n",
    "    start = int(position.split(':')[1].split('-')[0])\n",
    "    end = int(position.split(':')[1].split('-')[1])\n",
    "    \n",
    "    try:\n",
    "\n",
    "        gdf = cnv_info.groupby('Chr').get_group(chrom)\n",
    "\n",
    "        # remove all the ones in region that are singleton dels in that one person, excluding other sites\n",
    "\n",
    "        gdf = gdf[(gdf.Start > start) & (gdf.End < end) & (gdf['diff_from_mode_uuids_str'] == UUID)]\n",
    "        print 'somatic sites marked:'\n",
    "        print gdf.shape\n",
    "\n",
    "        ind = gdf[gdf.cnv_class == svtype].index.tolist()\n",
    "        \n",
    "        if len(ind) > 0:\n",
    "            cnv_info['somatic'] = False\n",
    "            cnv_info.loc[ind, 'somatic'] = True\n",
    "    except:\n",
    "        cnv_info['somatic'] = False\n",
    "        \n",
    "    return cnv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_length_annotations(cnv_info):\n",
    "    \n",
    "    # ensure that uuids list order is matching the order of the df before processing\n",
    "    \n",
    "    \n",
    "    cnv_info['Length'] = cnv_info.End.astype(int) - cnv_info.Start.astype(int)\n",
    "    \n",
    "    size_bins = np.arange(1.6, 6, 0.2 )\n",
    "    cnv_info['log_length']= np.log10(cnv_info.Length)\n",
    "    cnv_info['log_size_bins']=pd.cut(cnv_info.log_length, size_bins, labels=size_bins[1:])\n",
    "    \n",
    "    return cnv_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_info_LQ(df, fcns):\n",
    "    \"\"\"annotate the LQ counts for each site from LQ matrix onto info df,\n",
    "    returns info df with new cols\"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    g =  fcns.apply(pd.value_counts, axis = 1)\n",
    "    cols = g.columns.tolist()\n",
    "    \n",
    "    # if all pass\n",
    "    for i in  ['LQ', 'PASS']:\n",
    "        if i not in cols:\n",
    "            g[i] = 0\n",
    "    \n",
    "    \n",
    "    g['LQ'] = g.LQ.fillna(0)\n",
    "    g['PASS'] = g.PASS.fillna(0)\n",
    "    \n",
    "    df['LQ_NSAMP'] = g['LQ']\n",
    "    df['PASS_NSAMP'] =  g['PASS']\n",
    "    \n",
    "    inds = fcns.index.tolist()\n",
    "    tdf = fcns.T\n",
    "    data = []\n",
    "    for i in inds:\n",
    "        t  = (tdf[i] == 'LQ')\n",
    "        t = t[t]\n",
    "        \n",
    "        if t.shape[0] != 0:\n",
    "            samps = t.index.tolist()\n",
    "            data.append(samps)\n",
    "        else:\n",
    "            data.append(False)\n",
    "    \n",
    "    df['LQ_samps']  = data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lq_union(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    lq_cols = ['lq_samps_hipsci_fib', 'lq_samps_hipsci_ipsc', 'lq_samps_ipscore_fb']\n",
    "    \n",
    "    \n",
    "    lq_cols2 = ['lq_samps_hipsci_fib', 'lq_samps_ipscore_fb']\n",
    "    \n",
    "    def union_of_cols(df, lq_cols):\n",
    "\n",
    "        in_data = df[lq_cols].values\n",
    "        out_unions = []\n",
    "        num_lq  = []\n",
    "        for i in in_data:\n",
    "            s = set()\n",
    "            for k in i:\n",
    "                if type(k) == bool:\n",
    "                    pass\n",
    "                else:\n",
    "                    s.update(set(k))\n",
    "            out_unions.append(s)\n",
    "\n",
    "\n",
    "            num_lq.append(len(s))\n",
    "        return out_unions, num_lq\n",
    "    \n",
    "\n",
    "    out_unions, num_lq = df.pipe(union_of_cols, lq_cols)\n",
    "    df['lq_union_all']  = out_unions\n",
    "    df['num_union_all'] = num_lq\n",
    "    \n",
    "    df['lq_union_all_str']  = [\",\".join(list(i)) for i in out_unions]\n",
    "    \n",
    "    \n",
    "    out_unions, num_lq = df.pipe(union_of_cols, lq_cols2)\n",
    "    df['lq_union_bf']  = out_unions\n",
    "    df['num_union_bf'] = num_lq\n",
    "    \n",
    "    df['lq_union_bf_str']  = [\",\".join(list(i)) for i in out_unions]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate_specific_set_of_samples(cnv_info, cns, uuids, sex_dict, suffix = 'FALSE', lq_dict = False):\n",
    "    \n",
    "    cns = cns[uuids]\n",
    "    females = [i for i in uuids if sex_dict[i] == 'F']\n",
    "    males = [i for i in uuids if sex_dict[i] == 'M']\n",
    "    \n",
    "     # transpose the df to increase speed (accessing columns is faster than rows\n",
    "    cns_trans = cns.T\n",
    "    data_summary, maf_data = gs_annotations(cns_trans, uuids, sex_dict, lq_dict=lq_dict)\n",
    "    \n",
    "    \n",
    "    out_cols = ['ID','cn_mode', 'cn_mode_male', 'cn_mode_female', 'diff_from_mode', 'percent_diff_from_mode',\n",
    "                'diploid_alleles', 'count_alleles', 'alleles_dist', 'alleles_dist_males',\n",
    "                'alleles_dist_females','variant_alleles', 'variant_allele_count',\n",
    "                'max_allele', 'min_allele', 'cnv_type','min_predicted_alleles', 'cnv_class', \n",
    "                'cnv_subclass', 'diff_mode_uuids', 'lq_samps', 'num_lq', 'num_pass', 'all_lq', 'MAF', 'NONREF_AF']\n",
    "    \n",
    "    \n",
    "    if suffix == 'FALSE':\n",
    "        suffix = ''\n",
    "    \n",
    "    \n",
    "    cols = data_summary.keys()\n",
    "    df_main = pd.DataFrame.from_dict(data_summary)\n",
    "    df_main = df_main[out_cols]\n",
    "    df_main = df_main.set_index('ID')\n",
    "    \n",
    "    col_names = [ c + suffix for c in df_main.columns]\n",
    "    df_main.columns = col_names\n",
    "    \n",
    "    cols = ['NNREF', 'ALTAF', 'REFAF', 'MAF', 'Minor_Allele', 'NREF', 'ID', 'cnv_class']\n",
    "    maf_df = pd.DataFrame(maf_data, columns=cols)\n",
    "    maf_df = maf_df.set_index('ID')\n",
    "    col_names = [ c + suffix for c in maf_df.columns]\n",
    "    maf_df.columns = col_names\n",
    "    \n",
    "        \n",
    "    return df_main, maf_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_sample_set_annotations(cnv_info, cns, fcns, uuid_lists, suffix_lists, sex_dict, lq_adjust = False, lq_union = False, add_to_info = True):\n",
    "    \n",
    "    if lq_adjust:\n",
    "        if 'LQ_samps' in cnv_info.columns.tolist():\n",
    "            lq_dict = cnv_info['LQ_samps'].to_dict()\n",
    "        else:\n",
    "            cnv_info =  cnv_info.pipe(annotate_info_LQ, fcns)\n",
    "            lq_dict = cnv_info['LQ_samps'].to_dict()\n",
    "        \n",
    "    else:\n",
    "        lq_dict = False\n",
    "    \n",
    "    dfs_general = []\n",
    "    dfs_maf = []\n",
    "    \n",
    "    for ul, sl in zip(uuid_lists, suffix_lists):\n",
    "        print 'annotating of {}'.format(sl)\n",
    "        gen_info, maf_info = annotate_specific_set_of_samples(cnv_info, cns, ul, sex_dict, sl, lq_dict=lq_dict)\n",
    "        dfs_general.append(gen_info)\n",
    "        dfs_maf.append(maf_info)\n",
    "         \n",
    "    \n",
    "    to_add = pd.concat(dfs_general, axis = 1)\n",
    "    maf_all = pd.concat(dfs_maf, axis = 1)\n",
    "    \n",
    "    if add_to_info:\n",
    "        for c in to_add.columns:\n",
    "            cnv_info[c] = to_add[c]\n",
    "            \n",
    "            \n",
    "    if lq_union:\n",
    "        try:\n",
    "            cnv_info = cnv_info.pipe(get_lq_union)\n",
    "        except:\n",
    "            print 'could not annotate lq unions'\n",
    "       \n",
    "    \n",
    "    return cnv_info, maf_all, to_add\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# geno_all_with_stitch = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/gs_processing_V3/i2QTL_combined/cns_all_with_stitch.pkl')\n",
    "\n",
    "# sample_info = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/sample_info_combined/sample_info.pkl')\n",
    "\n",
    "# # subsets we will need for unifying genotype fields\n",
    "\n",
    "# samples_ipscore = sample_info[(sample_info.STUDY == 'iPSCORE')].WGS_ID.tolist()\n",
    "\n",
    "# samples_hipsci_fib = sample_info[(sample_info.STUDY == 'HipSci') & (sample_info.CELL_TYPE == 'Fibroblast')].WGS_ID.tolist()\n",
    "\n",
    "# info = pd.read_pickle('/frazer01/projects/hipsci/analysis/i2QTL-sv-analysis/private_output/gs_processing_V3/i2QTL_combined/gs_info_stitch_annot_final.pkl')\n",
    "\n",
    "# # lq_dict = info.LQ_samps.to_dict()\n",
    "\n",
    "# sex_dict = sample_info.SEX.to_dict()\n",
    "\n",
    "# geno_all_with_stitch = geno_all_with_stitch.reindex(info.index)\n",
    "\n",
    "# tran = geno_all_with_stitch[samples_ipscore].T\n",
    "\n",
    "# t,t2 = gs_annotations(tran, samples_ipscore, sex_dict, lq_dict=lq_dict)\n",
    "\n",
    "# cols = ['NNREF', 'ALTAF', 'REFAF', 'MAF', 'Minor_Allele', 'NREF', 'ID', 'cnv_class']\n",
    "# maf_df = pd.DataFrame(t2, columns=cols)\n",
    "\n",
    "# maf_df = maf_df.set_index('ID')\n",
    "\n",
    "# cols = ['ID','cn_mode', 'diff_from_mode', 'percent_diff_from_mode', 'diploid_alleles',\n",
    "#                 'diploid_alleles_males', 'diploid_alleles_females', \n",
    "#                 'count_alleles', \n",
    "#                'alleles_dist', 'variant_alleles', 'variant_allele_count', \n",
    "#                 'min_allele', 'max_allele', 'min_allele_males', 'max_allele_males', 'min_allele_females', 'max_allele_females', 'cnv_type','min_predicted_alleles', 'cnv_class', 'cnv_subclass', 'diff_mode_uuids', 'cn_mode_male', 'cn_mode_female', 'lq_samps', 'num_lq', 'num_pass', 'all_lq', 'pass_samps', 'num_pass_males', 'num_pass_females', 'bi_class']\n",
    "\n",
    "# tdf = pd.DataFrame.from_dict(t)\n",
    "\n",
    "# tdf = tdf.set_index(\"ID\", drop = False)\n",
    "# tdf = tdf[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_lists = [samples_ipscore, samples_hipsci_fib]\n",
    "# suff_list = ['_ipscore_fb', '_hipsci_fib']\n",
    "\n",
    "\n",
    "# info, dfs_maf, dfs_general = add_sample_set_annotations(info, geno_all_with_stitch, False, sample_lists, suff_list, sex_dict, lq_adjust=True, add_to_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_general[dfs_general.MAF_ipscore_fb != dfs_general.percent_diff_from_mode_ipscore_fb][['alleles_dist_ipscore_fb', 'MAF_ipscore_fb', 'percent_diff_from_mode_ipscore_fb']].percent_diff_from_mode_ipscore_fb.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_arguments_to_parser(parser):\n",
    "    \n",
    "    parser.add_argument(\"-cns\", \"--cns\", dest=\"cns\", metavar='<cns>', help=\"genome strip cns pickle (Copy Number States)\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-fcns\", \"--fcns\", dest=\"fcns\", metavar='<fcns>', help=\"genome strip fcns pickle (Filter Column for each sample/site)\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-info\", \"--info\", dest=\"info\", metavar='<info>', help=\"genome strip info pickle\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-s\", \"--samples\", dest=\"samples\", metavar='<fn_samples1,fn_samples2>', help=\"sets of samples to annotate\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-gender_map\", \"--gender_map\", dest=\"gender_map\", metavar='<gender_map>', help=\"gender file UUID Sex, tab delimited\", required=True)   \n",
    "    \n",
    "    parser.add_argument(\"-intersect\", \"--intersections\", dest=\"intersect\", metavar='<True/False>', help=\"intersect with MHC VDJ Centromeres, Telomeres\", required=False, default=True)\n",
    "    \n",
    "    parser.add_argument(\"-maf_only\", \"--maf_only\", dest=\"maf_only\", action = 'store_true', help=\"only annotate maf from a subset of samples, skip other annotations\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-LQ_adjust\", \"--lq_adjust\", dest=\"lq_adjust\", action = 'store_true', help=\"adjust for low qual samples during MAF calculations\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-LQ_union\", \"--lq_union\", dest=\"lq_union\", action = 'store_true', help=\"annotate the union of lq samples per site, num LQ\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-ss_suff\", \"--suffix_subsets\", dest=\"suffix_subsets\", metavar='<suff1,suff2,suff3>', help=\"suffixes to use for naming columns of annotated subsets of samples ex: unrelated, related\", required=True, default=False)\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-somatic\", \"--somatic\", dest=\"somatic\", metavar='<Sample,region,svtype>', help=\"annotate presence of a known somatic variant, svtype indicates which variant type the somatic variant is.  useful if you know that you have a somatic variant with other evidence such as arrays from different cell types on the same individuals\", required=False, default=False)\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-genes\", \"--genes\", dest=\"genes\", action = 'store_true', help=\"annotate intersection with gencode genes\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-conv_int\", \"--conv_int\", dest=\"convert_int\", action = 'store_true', help=\"force data in cns columns to be integer dtype\")\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-o\", \"--output_dir\", dest=\"output_dir\", metavar='<out_dir>', help=\"output directory for summary output\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-pre\", \"--prefix\", dest=\"prefix\", metavar='<prefix>', help=\"prefix to name files\", default = False)\n",
    "    \n",
    "    parser.add_argument(\"-file_suff\", \"--suffix\", dest=\"suffix\", metavar='<suffix>', help=\"prefix to name files\", default = False)\n",
    "    \n",
    "\n",
    "    parser.set_defaults(entry_point=run_from_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def command_parser():\n",
    "    parser = argparse.ArgumentParser(description= 'command line utility to annotate extracted info and genotypes from genome_strip_extract utility with various things such as gene intersections, minor allele frequency etc.')\n",
    "    add_arguments_to_parser(parser)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_from_args(args):\n",
    "    gs_cns = pd.read_pickle(args.cns)\n",
    "    gs_info = pd.read_pickle(args.info)\n",
    "    gs_fcns = pd.read_pickle(args.fcns)\n",
    "    \n",
    "    # ensure ordering is the same from the start\n",
    "    gs_cns = gs_cns.reindex(gs_info.index)\n",
    "    gs_fcns = gs_fcns.reindex(gs_info.index)\n",
    "    \n",
    "    \n",
    "    sample_files = args.samples\n",
    "    sample_files = sample_files.split(',')\n",
    "    \n",
    "    sample_lists = []\n",
    "    for fn in sample_files:\n",
    "        samples = [line.rstrip() for line in open(fn)]\n",
    "        sample_lists.append(samples)\n",
    "        \n",
    "    suffixes = args.suffix_subsets\n",
    "    suffixes = suffixes.split(',')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    gender_file = args.gender_map\n",
    "    \n",
    "    sex_dict = {line.rstrip().split()[0]:line.rstrip().split()[1] for line in open(gender_file)}\n",
    "   \n",
    "    \n",
    "    print 'starting annotation'\n",
    "    print CM.datestring(hour=True, minute=True)\n",
    "    \n",
    "    if args.convert_int:\n",
    "        for s in samples:\n",
    "            gs_cns[s] = gs_cns[s].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    output_location = args.output_dir\n",
    "    \n",
    "    if args.maf_only:\n",
    "        print \"annotating subset(s)\"\n",
    "        \n",
    "        gs_info, maf_df, to_add = add_sample_set_annotations(gs_info, gs_cns, gs_fcns, sample_lists, \n",
    "                                                             suffixes, sex_dict,lq_adjust=args.lq_adjust, \n",
    "                                                             lq_union = args.lq_union)\n",
    "    \n",
    "    else:\n",
    "        print 'annotating data subsets'\n",
    "        \n",
    "        gs_info, maf_df, to_add = add_sample_set_annotations(gs_info, gs_cns, gs_fcns, sample_lists, \n",
    "                                                             suffixes, sex_dict,\n",
    "                                                             lq_adjust=args.lq_adjust, lq_union = args.lq_union)\n",
    "        \n",
    "        gs_info = basic_length_annotations(gs_info)\n",
    "        \n",
    "        if args.intersect:\n",
    "            print \"annotating centromere/telomere distances, MHC, VDJ Regions\"\n",
    "            gs_info = annotate_filters(gs_info)\n",
    "    #         print gs_info\n",
    "\n",
    "        if args.somatic:\n",
    "            print \"annotating somatic variants\"\n",
    "            spl = args.somatic.split(',')\n",
    "            uuid = spl[0]\n",
    "            region = spl[1]\n",
    "            svtype = spl[2]\n",
    "            gs_info = annotate_somatic_var(gs_info, uuid, region, svtype)\n",
    "\n",
    "        if args.genes == True:\n",
    "            print \"annotating gencode genes\"\n",
    "            gs_info = annotate_gencode_genes(gs_info)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if args.suffix:\n",
    "        fn_info = os.path.join(output_location, 'gs_info' + args.suffix)\n",
    "        fn_cns = os.path.join(output_location, 'gs_cns' + args.suffix)\n",
    "        \n",
    "        var_name_info = 'gs_info' + args.suffix\n",
    "        var_name_cns  = 'gs_cns' + args.suffix\n",
    "        var_name_maf = 'gs_maf_bi' + args.suffix\n",
    "    \n",
    "    else:\n",
    "        fn_info = os.path.join(output_location, 'gs_info')\n",
    "        fn_cns = os.path.join(output_location, 'gs_cns')\n",
    "        var_name_info = 'gs_info'\n",
    "        var_name_cns  = 'gs_cns'\n",
    "        var_name_maf = 'gs_maf_bi'\n",
    "        \n",
    "    \n",
    "    print 'data annotated'\n",
    "    # is this necessary- probably don't need to save the cns frame again\n",
    "#     if args.cns_reset_ind:\n",
    "#         CM.save_dataframe(var_name_cns, gs_cns, output_location, print_vars_recorded_loc=False, reset_index = True, index = False)\n",
    "    \n",
    "#     else:\n",
    "#         CM.save_dataframe(var_name_cns, gs_cns, output_location, print_vars_recorded_loc=False)\n",
    "    \n",
    "    CM.save_dataframe(var_name_info, gs_info, output_location, print_vars_recorded_loc=False)\n",
    "    CM.save_dataframe(var_name_maf, maf_df, output_location, print_vars_recorded_loc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = command_parser()\n",
    "    args = parser.parse_args()\n",
    "    sys.exit(args.entry_point(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
