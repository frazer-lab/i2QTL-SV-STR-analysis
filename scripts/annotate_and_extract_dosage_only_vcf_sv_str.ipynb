{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import djPyBio as DJ\n",
    "from djPyBio import Common as CM\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy \n",
    "import pybedtools as pbt\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "import itertools\n",
    "import tempfile\n",
    "import six\n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import argparse\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from mpl_toolkits.axes_grid1 import  make_axes_locatable\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_header_end(fn):\n",
    "    \"\"\" find header end line number of vcf or gzipped vcf\"\"\"\n",
    "\n",
    "    if fn.split('.').pop() == 'gz':\n",
    "        import gzip\n",
    "        F = gzip.open(fn, 'rU')\n",
    "    else:\n",
    "        F = open(fn, 'rU')\n",
    "\n",
    "\n",
    "    count = 0\n",
    "    for line in F:\n",
    "        count +=1\n",
    "        try: \n",
    "            spl = line.split('\\t')\n",
    "            spl0 = spl[0] \n",
    "            if spl[0]==\"#CHROM\":\n",
    "                F.close()\n",
    "                return count\n",
    "            if count > 2000:\n",
    "                F.close()\n",
    "                return 'incomplete or missing header, or very long header'\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    F.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_info_col(t, lab, type_out = str, alternative = 'None'):\n",
    "    t = t.split(';')\n",
    "    # filter out the tags with no keyword, if any\n",
    "    t = [i for i in t if i.find('=') != -1]\n",
    "    cols = [i.split('=')[0] for i in t]\n",
    "    try:\n",
    "        vals = [i.split('=')[1] for i in t]    \n",
    "    except:\n",
    "        return \"PARSE_ERROR\"\n",
    "    try:\n",
    "        ind = cols.index(lab)\n",
    "        v = vals[ind]\n",
    "        \n",
    "        try:\n",
    "            return type_out(v)\n",
    "        except:\n",
    "            return alternative\n",
    "    except:\n",
    "        return 'Column_Not_Present'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_format_col(t, col, lab, type_out = str, alternative = 'None', change_dict = False):\n",
    "    \"\"\" use the format column to pull out info of a specific VCF record\n",
    "    in a genotyping matrix (unparsed)\"\"\"\n",
    "    \n",
    "    f= t['FORMAT']\n",
    "    c = t[col]\n",
    "    c  = c.split(':')\n",
    "    f = f.split(':')\n",
    "    \n",
    "    try:\n",
    "        ind = f.index(lab)\n",
    "        v = c[ind]\n",
    "        try:\n",
    "            if change_dict:\n",
    "                try:\n",
    "                    v = change_dict.get(v, v)\n",
    "                except:\n",
    "                    return 'ERROR'\n",
    "            \n",
    "            return type_out(v)\n",
    "        except:\n",
    "            return alternative\n",
    "            \n",
    "    except:\n",
    "        return 'Column_Not_Present'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_format_mod(t, col, lab, except_out = 'None'):\n",
    "    \"\"\" use the format column to pull out info of a specific VCF record\n",
    "    in a genotyping matrix (unparsed)\"\"\"\n",
    "    \n",
    "    f= t['FORMAT']\n",
    "    c = t[col]\n",
    "    c  = c.split(':')\n",
    "    f = f.split(':')\n",
    "    \n",
    "    try:\n",
    "        ind = f.index(lab)\n",
    "        v = c[ind]\n",
    "        return v\n",
    "    except:\n",
    "        return except_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_extract(df,chrom, start, end, contained = True):\n",
    "    \n",
    "    if contained:\n",
    "        return df[(df.Chr==chrom) & (df.POS >= start) & (df.END <= end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geno_fields(labs, samples, lin_spl, header_dict, format_dict):\n",
    "    gts_out = [{} for l in labs]\n",
    "    missing_samps = []\n",
    "    for s in samples:\n",
    "        d = lin_spl[header_dict[s]].split(':')\n",
    "        # cases where we don't have format info for all categories\n",
    "        if len(d) == 1:\n",
    "            if d[0] == '.':\n",
    "                missing_samps.append(s)\n",
    "        \n",
    "        for i,l in enumerate(labs):\n",
    "            if len(d) == 1:\n",
    "                if d[0] == '.':\n",
    "                    gt = './.'\n",
    "                \n",
    "            else:\n",
    "                gt = d[format_dict[l]]\n",
    "                if gt in ['.', './.']:\n",
    "                    gt = './.'\n",
    "                    missing_samps.append(s)\n",
    "                \n",
    "                \n",
    "            \n",
    "            gts_out[i][s] = gt\n",
    "    missing_samps = list(set(missing_samps))\n",
    "    return gts_out, missing_samps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_div(x, y, alt=0):\n",
    "    try:\n",
    "        return x/y\n",
    "    except:\n",
    "        return alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_min_dict(d, samples):\n",
    "    v = [d[s] for s in samples]\n",
    "    v = [float(i) for i in v if i != './.']\n",
    "    max_v = round(max(v),4)\n",
    "    min_v = round(min(v), 4)\n",
    "    \n",
    "    return max_v, min_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_counts_to_per_sample(d, samples, cumulative_dict):\n",
    "    \n",
    "    for s in samples:\n",
    "        c = str(d[s])\n",
    "        \n",
    "        if c== '0':\n",
    "            cat = 'REF'\n",
    "        \n",
    "        elif c in ['./.', '.']:\n",
    "            cat = 'MISSING'\n",
    "        \n",
    "        else:\n",
    "            cat = 'NREF'\n",
    "        \n",
    "        cumulative_dict[s][cat] = cumulative_dict[s].get(cat, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pair_concordance(pair_samples, data_dict):\n",
    "         \n",
    "    number_with_var = 0\n",
    "    number_concordant_with_var = 0\n",
    "    number_discordant_with_var = 0\n",
    "    number_missing = 0\n",
    "    per_pair_data = []\n",
    "    for tp in pair_samples:\n",
    "\n",
    "        vals =  map(str, [data_dict[tp[0]], data_dict[tp[1]]])\n",
    "\n",
    "        # check one way- first twin- for variant\n",
    "        if vals[0] == './.':\n",
    "            number_missing +=1\n",
    "            per_pair_data.append('MISSING')\n",
    "        \n",
    "        if vals[0] not in ['0|0', './.', '0']:\n",
    "\n",
    "            number_with_var +=1\n",
    "            if vals[0] == vals[1]:\n",
    "#                 tps_concordant.append(\"_\".join(tp))\n",
    "                number_concordant_with_var +=1\n",
    "                per_pair_data.append('CONCORDANT')\n",
    "            else:\n",
    "#                 tps_discordant.append(\"_\".join(tp))\n",
    "                number_discordant_with_var +=1 \n",
    "                per_pair_data.append('DISCORDANT')\n",
    "        elif vals[0] in ['0|0', '0']:\n",
    "            per_pair_data.append('REF')\n",
    "\n",
    "    if number_with_var > 0:\n",
    "        # replication rate- ranges from 0-100% 100% means every variant is a match\n",
    "        replication_rate = 1 - (number_discordant_with_var/number_with_var)\n",
    "    else:\n",
    "        replication_rate = 'None'\n",
    "    \n",
    "    if number_with_var > 0:\n",
    "        return [per_pair_data, number_with_var, number_concordant_with_var, number_discordant_with_var,\n",
    "                number_missing, replication_rate]\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_alt_allele_freq(gts_dict, samples, chrom, num_samples):\n",
    "    \"\"\" calculate alt allele freq \"\"\"\n",
    "    \n",
    " \n",
    "    #uuids containing the 1 allele\n",
    "    non_ref = 0\n",
    "    non_ref_uuids = []\n",
    "\n",
    "    #uuids containing the 0 allele \n",
    "    ref = 0\n",
    "    ref_uuids = []\n",
    "\n",
    "\n",
    "    # for chroms that are diploid\n",
    "    # correct for allelic probs on sex chroms\n",
    "\n",
    "    missing = 0\n",
    "    alleles_dist = {}\n",
    "    \n",
    "    for s in samples:\n",
    "        c = str(gts_dict[s])\n",
    "        \n",
    "#         sex = sex_dict[s]\n",
    "        \n",
    "        alleles_dist[c] = alleles_dist.get(c, 0) + 1\n",
    "        \n",
    "        \n",
    "        if c == './.':\n",
    "            missing +=1\n",
    "        \n",
    "        if c not in ['0|0','./.', '0']:\n",
    "            non_ref +=1\n",
    "            non_ref_uuids.append(s)\n",
    "\n",
    "        if c in ['0|0', '0']:\n",
    "            ref +=1\n",
    "            ref_uuids.append(s)\n",
    "\n",
    "\n",
    "    percent_missing = round((missing/num_samples), 3)\n",
    "    \n",
    "    if (ref == 0) & (non_ref > 0): \n",
    "        NNREF_Freq = 1.0\n",
    "          \n",
    "    else:\n",
    "        NNREF_Freq = round(safe_div(non_ref, ref, alt= 0), 4)\n",
    "    \n",
    "\n",
    "    \n",
    "    out_names = ['NREF', 'REF', 'NMissing', 'NNREF_UUIDs','NNREF_AF', 'ALLELES_DIST', 'PERC_MISSING']\n",
    "    alleles_dist = \",\".join([\"{}:{}\".format(i,k) for i,k in alleles_dist.iteritems()])\n",
    "    out_data = [non_ref, ref, missing, \",\".join(non_ref_uuids), NNREF_Freq, alleles_dist, percent_missing]\n",
    "    data_dict = dict(zip(out_names, out_data))\n",
    "    return data_dict, out_names, out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_per_pair(df):\n",
    "    df = df.copy()\n",
    "    df = df.T\n",
    "    df['RR'] = df['CONCORDANT'] / (df['CONCORDANT'] + df['DISCORDANT'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_per_sample(df):\n",
    "    df = df.copy()\n",
    "    df = df.T\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(features, minimum = 0, maximum = 2):\n",
    "    min_features = min(features)\n",
    "    max_features = max(features)\n",
    "    \n",
    "    if max_features - min_features == 0:\n",
    "        return\n",
    "    \n",
    "    def transform(x, min_features, max_features, min_target, max_target):\n",
    "                \n",
    "        xstd = (x - min_features) / (max_features - min_features)\n",
    "        xscaled = xstd * (max_target - min_target) + min_target\n",
    "        \n",
    "        return xscaled\n",
    "        \n",
    "    features_out = [transform(i, min_features, max_features, minimum, maximum) for i in features]\n",
    "    return features_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rank_dict(ds_dict, sample_subset, type_out = int):\n",
    "    \"\"\"adjusted dosages - rank the dosages and put them on a 0-2 scale\"\"\"\n",
    "    \n",
    "    values = []\n",
    "    for k,v in ds_dict.iteritems():\n",
    "        \n",
    "        if k in sample_subset:\n",
    "            if v in ['./.', '.']:\n",
    "                pass\n",
    "            else:\n",
    "                values.append(type_out(v))\n",
    "\n",
    "    rank_vals = stats.rankdata(values)\n",
    "    \n",
    "    scale_ranks = MinMaxScaler(rank_vals)\n",
    "    scale_ranks = [round(i, 4) for i in scale_ranks]\n",
    "    rank_dict = dict(zip(map(str, values), scale_ranks))\n",
    "    return rank_dict\n",
    "\n",
    "def get_adjusted_ds_dict(ds_dict, rank_dict, type_in = int):\n",
    "    \n",
    "    adj_ds_dict = {}\n",
    "    \n",
    "    for k,v in ds_dict.iteritems():\n",
    "        try:\n",
    "            key_out = str(type_in(v))\n",
    "        except:\n",
    "            key_out = v\n",
    "            \n",
    "        rank_convert = rank_dict.get(key_out, '.')\n",
    "        adj_ds_dict[k] = rank_convert\n",
    "        \n",
    "    return adj_ds_dict\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_dict_biallelic_genotype(gt_dict, svtype):\n",
    "    \"\"\" compute the dosage from biallelic genotypes \"\"\"\n",
    "    \n",
    "    convert_dict_dup = {'0/0': 0, '0/1':1,  '1/1': 2}\n",
    "    convert_dict_del = {'0/0': 2, '0/1':1,  '1/1': 0}\n",
    "    ds_dict = {}\n",
    "    if svtype == 'DUP':\n",
    "        for k,v in gt_dict.iteritems():\n",
    "            ds_dict[k] = convert_dict_dup.get(v, '.')\n",
    "    \n",
    "    elif svtype in ['DEL', 'rMEI']:\n",
    "        for k,v in gt_dict.iteritems():\n",
    "            ds_dict[k] = convert_dict_del.get(v, '.')\n",
    "            \n",
    "    else:\n",
    "        # MOBILE ELEMENTS\n",
    "        for k,v in gt_dict.iteritems():\n",
    "            ds_dict[k] = convert_dict_dup.get(v, '.')\n",
    "            \n",
    "    return ds_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_maf_dosage(ds_dict, samples):\n",
    "    s = set(samples)\n",
    "    ds_dict_sub = {k:v for k,v in ds_dict.iteritems() if k in s}\n",
    "    vals = ds_dict_sub.values()\n",
    "    ignore = {'./.', '.'}\n",
    "    vals_corrected = [i for i in vals if i not in ignore]\n",
    "    C = Counter(vals_corrected)\n",
    "    mc = C.most_common()\n",
    "    try:\n",
    "        mc_allele, count_mc_allele = mc[0]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    if len(mc) == 0:\n",
    "            num_passing = 0\n",
    "            num_alt = 0\n",
    "            mc_allele = './.'\n",
    "            count_mc_allele = len(ds_dict_sub)\n",
    "\n",
    "    else:\n",
    "        num_passing = len(vals_corrected)\n",
    "        num_alt = num_passing - count_mc_allele\n",
    "        \n",
    "    if num_alt > 0:\n",
    "        maf = num_alt/num_passing\n",
    "    \n",
    "    else:\n",
    "        maf = 0\n",
    "    \n",
    "    alleles_dist = {} \n",
    "    for s in samples:\n",
    "        c = str(ds_dict[s])\n",
    "        alleles_dist[c] = alleles_dist.get(c, 0) + 1\n",
    "    \n",
    "    alleles_dist = \",\".join([\"{}:{}\".format(i,k) for i,k in alleles_dist.iteritems()])\n",
    "    return maf, count_mc_allele, mc_allele, num_passing, num_alt, alleles_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_vcf_and_annotate(fn, out_dir, sample_subset, fn_out, exclude = False, include = False):\n",
    "    \n",
    "    header_end = find_header_end(fn)\n",
    "    \n",
    "    count = 0\n",
    "    progress_level = 0\n",
    "    progress_increment = 50000\n",
    "    \n",
    "    \n",
    "    if fn.split('.').pop() == 'gz':\n",
    "        F = gzip.open(fn, 'rU')\n",
    "    else:\n",
    "        F = open(fn, 'rU')\n",
    "    \n",
    "    fn_annotated_vcf = os.path.join(out_dir, fn_out)\n",
    "    fn_out_vars = os.path.join(out_dir, 'variants_outputted.tsv')\n",
    "#     fn_maf = os.path.join(out_dir, 'hipstr_maf_rna.tsv')\n",
    "    out_vars_file = open(fn_out_vars, 'w')\n",
    "    annotated_vcf = open(fn_annotated_vcf, 'w')\n",
    "#     maf_file = open(fn_maf, 'w')\n",
    "    \n",
    "    chroms = [str(i) for i in range(1,23)] + ['X', 'Y']\n",
    "    \n",
    "\n",
    "#     IDs_set = set(IDs)\n",
    "\n",
    "    if exclude:\n",
    "        exclude = set([i.rstrip() for i in open(exclude, 'r')])\n",
    "        \n",
    "    if include:\n",
    "        include = set([i.rstrip() for i in open(include, 'r')])\n",
    "    \n",
    "    count_missing = 0\n",
    "    num_variants = 0\n",
    "    num_variants_out = 0\n",
    "    d = datetime.datetime.now()\n",
    "    ts = d.strftime('%D- %H:%M')\n",
    "    print \"Starting Variant Processing: {}\".format(ts)\n",
    "    \n",
    "#     info_fields = 'INFRAME_PGEOM INFRAME_UP INFRAME_DOWN OUTFRAME_PGEOM OUTFRAME_UP OUTFRAME_DOWN BPDIFFS START END AN REFAC AC NSKIP NFILT DP DSNP DSTUTTER DFLANKINDEL'.split()\n",
    "            \n",
    "    add_id = False\n",
    "    add_info = False\n",
    "    count_num_length = 0\n",
    "    for line in F:\n",
    "        \n",
    "        if progress_level == progress_increment:\n",
    "            d = datetime.datetime.now()\n",
    "            ts = d.strftime('%D- %H:%M')\n",
    "            print \"processed {} variants {}\".format(count, ts)\n",
    "            progress_level = 0\n",
    "            \n",
    "        progress_level +=1\n",
    "\n",
    "\n",
    "        line = line.rstrip()\n",
    "        lin_spl = line.split('\\t')\n",
    "\n",
    "        if count < header_end-1:\n",
    "            if not add_id:\n",
    "                if line.find('##FORMAT') == 0:\n",
    "                    add_id= True\n",
    "                    l = '##FORMAT=<ID=DS,Number=1,Type=String,Description=\"Dosage 0-2 encoding of genotypes (0/0, 0/1, 1/1 - 0, 1, 2) (MELT) or ranked copy number (GS, GS_LCNV)/allele balance(LUMPY)/change in length (HipSTR)\">'\n",
    "                    annotated_vcf.write(l + '\\n')\n",
    "            else:\n",
    "                # remove the other format columns\n",
    "                if line.find('##FORMAT') == 0:\n",
    "                    count += 1\n",
    "                    continue\n",
    "            \n",
    "            if not add_info:\n",
    "                if line.find('##INFO') == 0:\n",
    "                    add_info= True\n",
    "         \n",
    "                    \n",
    "            annotated_vcf.write(line + '\\n')\n",
    "            \n",
    "\n",
    "        if count == header_end-1:\n",
    "\n",
    "            \n",
    "            header = copy.deepcopy(lin_spl)\n",
    "            header_dict = {l:i for l,i in zip(lin_spl, range(0, len(lin_spl)))}\n",
    "            info_head = header[:9]\n",
    "            samples = header[9:]\n",
    "            info_cols = header[:9]\n",
    "            sample_order_dict = {s:header.index(s) for s in samples}\n",
    "            \n",
    "            try:\n",
    "                reodered_samples = [header[sample_order_dict[i]] for i in sample_subset]\n",
    "            except:\n",
    "                print sample_order_dict\n",
    "                print desired_samples\n",
    "                print samples\n",
    "                break\n",
    "            \n",
    "            header_mod = info_cols + reodered_samples\n",
    "            annotated_vcf.write(\"\\t\".join(header_mod) + '\\n')\n",
    "            header_cols = ['ID', 'CALLER', 'MAF_RNA', 'SVTYPE']\n",
    "            out_vars_file.write(\"\\t\".join(header_cols) +'\\n')\n",
    "            \n",
    "            \n",
    "            count +=1\n",
    "            continue\n",
    "\n",
    "            \n",
    "\n",
    "        elif count > header_end:\n",
    "\n",
    "           \n",
    "\n",
    "            format_fields = lin_spl[header_dict['FORMAT']].split(':')\n",
    "            format_dict = {l:i for l,i in zip(format_fields, range(0, len(format_fields)))}\n",
    "\n",
    "            POS = lin_spl[header_dict['POS']]\n",
    "            ID = lin_spl[header_dict['ID']]\n",
    "            INFO = lin_spl[header_dict['INFO']]\n",
    "            chrom = str(lin_spl[header_dict['#CHROM']])\n",
    "            FILTER = str(lin_spl[header_dict['FILTER']])\n",
    "            \n",
    "            if exclude:\n",
    "                if ID in exclude:\n",
    "                    num_variants +=1\n",
    "                    count += 1\n",
    "                    continue\n",
    "                \n",
    "            if include:\n",
    "                if ID in include:\n",
    "                    num_variants +=1\n",
    "                    pass\n",
    "                else:\n",
    "                    num_variants +=1\n",
    "                    count += 1\n",
    "                    continue\n",
    "                    \n",
    "\n",
    "            cols_info_extracted = ['SVTYPE', 'CALLER']\n",
    "            cols_dict = dict(zip(cols_info_extracted, range(0, len(cols_info_extracted))))\n",
    "            info_out = []\n",
    "            info_cols_dict = {}\n",
    "            for l in cols_info_extracted:\n",
    "                c = parse_info_col(INFO, l)\n",
    "                info_out.append(c)\n",
    "                info_cols_dict[l] = c\n",
    "\n",
    "                \n",
    "#                 try:\n",
    "#                     maf = float(info_cols_dict['MAF_RNA'])\n",
    "#                 except:\n",
    "#                     print ID, INFO\n",
    "#                     break\n",
    "\n",
    "            caller = info_cols_dict['CALLER']\n",
    "            svtype = info_cols_dict['SVTYPE']\n",
    "\n",
    "#             if (maf > 0.01) & (FILTER == 'PASS'):\n",
    "            out_vars_file.write(\"\\t\".join(map(str, [ID, caller, svtype])) + '\\n')\n",
    "\n",
    "        # for all samples\n",
    "\n",
    "            if caller == 'LUMPY':\n",
    "                fields_desired = ['AB']\n",
    "                geno_fields_dict = {fields_desired[i]:i for i in range(0, len(fields_desired))}\n",
    "                geno_extracted, missing_samps_ab = get_geno_fields(fields_desired, samples, lin_spl, \n",
    "                                                            header_dict, format_dict)\n",
    "                ab_dict = geno_extracted[geno_fields_dict['AB']]\n",
    "\n",
    "                fields_desired = ['GT']\n",
    "                geno_fields_dict = {fields_desired[i]:i for i in range(0, len(fields_desired))}\n",
    "                geno_extracted, missing_samps_gt = get_geno_fields(fields_desired, samples, lin_spl, \n",
    "                                                            header_dict, format_dict)\n",
    "                gt_dict = geno_extracted[geno_fields_dict['GT']]\n",
    "\n",
    "                ab_dict = {k:(v.replace('./.', '0') if k not in missing_samps_gt else v) \n",
    "                               for k,v in ab_dict.iteritems()}\n",
    "\n",
    "                try:\n",
    "\n",
    "                    rank_dict = get_rank_dict(ab_dict, sample_subset, type_out= float)\n",
    "                    out_dict = get_adjusted_ds_dict(ab_dict, rank_dict, type_in=float)\n",
    "\n",
    "                except:\n",
    "                    print ID, ab_dict\n",
    "                    break\n",
    "\n",
    "            if caller in ['GS', 'GS_LCNV']:\n",
    "                try:\n",
    "                    fields_desired = ['CN']\n",
    "                    geno_fields_dict = {fields_desired[i]:i for i in range(0, len(fields_desired))}\n",
    "                    geno_extracted, missing_samps = get_geno_fields(fields_desired, samples, lin_spl, \n",
    "                                                            header_dict, format_dict)\n",
    "                except:\n",
    "                    print ID, format_fields, \n",
    "                    break\n",
    "\n",
    "                ab_dict = geno_extracted[geno_fields_dict['CN']]\n",
    "                \n",
    "                try:\n",
    "                    rank_dict = get_rank_dict(ab_dict, sample_subset, type_out = int)\n",
    "                    out_dict = get_adjusted_ds_dict(ab_dict, rank_dict, type_in = int)\n",
    "                except:\n",
    "                    print ID, ab_dict\n",
    "                    break\n",
    "                    \n",
    "                    \n",
    "            if caller == 'HipSTR':\n",
    "                try:\n",
    "                    fields_desired = ['BPS']\n",
    "                    geno_fields_dict = {fields_desired[i]:i for i in range(0, len(fields_desired))}\n",
    "                    geno_extracted, missing_samps = get_geno_fields(fields_desired, samples, lin_spl, \n",
    "                                                            header_dict, format_dict)\n",
    "                except:\n",
    "                    print ID, format_fields, \n",
    "                    break\n",
    "\n",
    "\n",
    "                ab_dict = geno_extracted[geno_fields_dict['BPS']]\n",
    "                try:\n",
    "\n",
    "                    rank_dict = get_rank_dict(ab_dict, sample_subset, type_out = int)\n",
    "                    out_dict = get_adjusted_ds_dict(ab_dict, rank_dict, type_in = int)\n",
    "                except:\n",
    "                    print ID, ab_dict\n",
    "                    break\n",
    "\n",
    "\n",
    "            if caller == 'MELT':\n",
    "                fields_desired = ['GT']\n",
    "                geno_fields_dict = {fields_desired[i]:i for i in range(0, len(fields_desired))}\n",
    "                geno_extracted, missing_samps = get_geno_fields(fields_desired, samples, lin_spl, \n",
    "                                                            header_dict, format_dict)\n",
    "\n",
    "                gt_dict = geno_extracted[geno_fields_dict['GT']]\n",
    "                out_dict = get_ds_dict_biallelic_genotype(gt_dict, svtype)\n",
    "\n",
    "\n",
    "            # set the format col to just DS\n",
    "            lin_spl[header_dict['FORMAT']] = 'DS'\n",
    "            lin_spl[header_dict['ALT']] = '<CNV>'\n",
    "            \n",
    "            info_cols = lin_spl[:9]\n",
    "\n",
    "            try:\n",
    "                reodered_samples = [out_dict[s] for s in sample_subset]\n",
    "            except:\n",
    "                print ID, sample_subset, len(sample_subset), out_dict\n",
    "                break\n",
    "\n",
    "            out_line_mod = info_cols + reodered_samples\n",
    "            annotated_vcf.write(\"\\t\".join(map(str, out_line_mod)) + '\\n')\n",
    "\n",
    "            num_variants_out +=1\n",
    "\n",
    "                      \n",
    "        count +=1\n",
    "    annotated_vcf.close()\n",
    "    out_vars_file.close()\n",
    "    print \"number of variants processed: {}\".format(num_variants)\n",
    "    print \"number of variants outputted: {}\".format(num_variants_out)\n",
    "\n",
    "    d = datetime.datetime.now()\n",
    "    ts = d.strftime('%D- %H:%M')\n",
    "    print \"Completed Variant Processing - subsetted to dosage only: {}\".format(ts)\n",
    "    print 'COMPLETE'\n",
    "    print 'files generated: {}'.format(fn_annotated_vcf)\n",
    "    print fn_out_vars\n",
    "    return\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arguments_to_parser(parser):\n",
    "    \n",
    "\n",
    "    parser.add_argument(\"-vcf\", \"--vcf\", dest=\"vcf_file\", metavar='<vcf_file>', help=\"vcf file from lumpy/speedseq pipeline, may be gzipped or not\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-s\", \"--samples\", dest=\"samples_fn\", metavar='<samples_fn>', help=\"file with samples to use to compute the maf and converted dosages\", required=False)\n",
    "    \n",
    "    parser.add_argument(\"-id_exclude\", \"--id_exclude_fn\", dest=\"id_exclude_fn\", metavar='<IDs to exclude in the final output>', help=\"file of pairs of IDs one per line to keep in the output\", required=False, default = False)\n",
    "    \n",
    "    parser.add_argument(\"-id_include\", \"--id_include_fn\", dest=\"id_include_fn\", metavar='<IDs to include in the final output>', help=\"file of pairs of IDs one per line to keep in the output\", required=False, default = False)\n",
    "    \n",
    "    parser.add_argument(\"-fn_out\", \"--fn_out\", dest=\"fn_out\", metavar='<file name of vcf output (NOT dir)>', help=\"file name of the vcf file- excluding the directory, just file name\", default = False, required=False)\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-o\", \"--output_dir\", dest=\"output_dir\", metavar='<out_dir>', help=\"output directory for summary output\", required=False, default = '')\n",
    "    \n",
    "    parser.set_defaults(entry_point=run_from_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def command_parser():\n",
    "    parser = argparse.ArgumentParser(description= 'command line utility to extract info and calculate replication rate for HipSTR vcf files')\n",
    "    add_arguments_to_parser(parser)\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_from_args(args):\n",
    "    vcf_fn = args.vcf_file\n",
    "    id_exclude_fn = args.id_exclude_fn\n",
    "    id_include_fn = args.id_include_fn\n",
    "    \n",
    "    samples_fn = args.samples_fn\n",
    "    fn_out = args.fn_out\n",
    "    out_dir = args.output_dir\n",
    "    \n",
    "        \n",
    "    samples = [line.rstrip() for line in open(samples_fn)]\n",
    "    process_vcf_and_annotate(vcf_fn, out_dir, samples, fn_out, exclude = id_exclude_fn, include = id_include_fn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = command_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    sys.exit(args.entry_point(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
