{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import djPyi2 as DJ\n",
    "from djPyi2 import Common as CM\n",
    "from djPyi2 import mpltools as axtools\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import pybedtools as pbt\n",
    "import ciepy\n",
    "import cardipspy as cpy\n",
    "import itertools\n",
    "import tempfile\n",
    "import six\n",
    "import networkx as nx\n",
    "import scipy.stats as stats\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "from mpl_toolkits.axes_grid1 import  make_axes_locatable\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "from scipy.stats import mode\n",
    "dy_name = 'gs_qc_analysis'\n",
    "\n",
    "private_out = os.path.join(DJ.root, 'private_output', dy_name)\n",
    "if not os.path.exists(private_out):\n",
    "    cpy.makedir(private_out)\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Square Test of the Possible batch effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nz_alleles(dist1, dist2):\n",
    "    nz1 = [z for z in dist1.keys() if dist1[z] != 0]\n",
    "    nz2 = [z for z in dist2.keys() if dist2[z] != 0]\n",
    "    \n",
    "    keys_to_test = list(set(nz1 + nz2))\n",
    "    keys_to_test = sorted(keys_to_test)\n",
    "    return keys_to_test\n",
    "\n",
    "def test_chi(keys, d1, d2):\n",
    "    \n",
    "    def add_missing_keys(keys, d):\n",
    "        d = d.copy()\n",
    "        for k in keys:\n",
    "            d[k] = d.get(k, 0)\n",
    "        return d\n",
    "    d1 = add_missing_keys(keys,d1)\n",
    "    d2 = add_missing_keys(keys,d2)\n",
    "    \n",
    "    v1 = [d1[z] for z in keys]\n",
    "    v2 = [d2[z] for z in keys]\n",
    "    g, p, dof, expctd = stats.chi2_contingency([v1, v2])\n",
    "    return p, v1, v2\n",
    "\n",
    "def get_chi_p(d1, d2):\n",
    "    keys = nz_alleles(d1, d2)\n",
    "    p,v1, v2 = test_chi(keys, d1, d2)\n",
    "    return p, keys, v1, v2\n",
    "\n",
    "\n",
    "def compare_var_sites(comp, suffix1, suffix2):\n",
    "    names = ['diploid_alleles', 'alleles_dist']\n",
    "    n1 = [\"_\".join([i, suffix1]) for i in names]\n",
    "    n2 = [\"_\".join([i, suffix2]) for i in names]\n",
    "    print n1\n",
    "    print n2\n",
    "    da1 = comp[n1[0]].tolist()\n",
    "    da2 = comp[n2[0]].tolist()\n",
    "    dist1 = comp[n1[1]].tolist()\n",
    "    dist2 = comp[n2[1]].tolist()\n",
    "    inds = comp.index.tolist()\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for d1, d2, ad1, ad2 in zip(da1, da2, dist1, dist2):\n",
    "        s1 = set(d1)\n",
    "        s2 = set(d2)\n",
    "        \n",
    "        same_gt = (ad1 == ad2)\n",
    "        same_alleles = False\n",
    "        s1_diff = set()\n",
    "        s2_diff = set()\n",
    "        if s1 == s2:\n",
    "            same_alleles = True\n",
    "        else:\n",
    "            s1_diff = s1.difference(s2)\n",
    "            s2_diff = s2.difference(s1)\n",
    "            \n",
    " \n",
    "        chi_p, keys, v1, v2 = get_chi_p(ad1, ad2)\n",
    "      \n",
    "        corr = np.corrcoef(v1, v2)[0][1]         \n",
    "        data.append([same_alleles, s1_diff, s2_diff, corr, chi_p, keys, same_gt])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['same_alleles', 'unique_alleles_1', 'unique_alleles_np', 'corr', 'chi_p', 'keys_compared', 'same_gts'], index=inds)\n",
    "    \n",
    "    df['ID'] = comp.index\n",
    "    df['ad_ipscore'] = comp[n1[1]]\n",
    "    df['ad_hipsci'] = comp[n2[1]]\n",
    "    \n",
    "    chi_p_thresh = 0.05 / df.shape[0]\n",
    "    df['filter_chi_p'] = df.chi_p < chi_p_thresh\n",
    "    \n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def prepare_allele_dist_batch(info):\n",
    "    \n",
    "    info = info.copy()\n",
    "    \n",
    "    data = []\n",
    "    for d1, x1, d2, x2 in zip(info.alleles_dist_ipscore_unrel.tolist(), \n",
    "                              info.num_lq_ipscore_unrel.tolist(),info.alleles_dist_hipsci_fib.tolist(),\n",
    "                             info.num_lq_hipsci_fib.tolist()):\n",
    "        d1 = copy.deepcopy(d1)\n",
    "        d1['LQ'] = x1\n",
    "        d2 = copy.deepcopy(d2)\n",
    "        d2['LQ'] = x2\n",
    "        \n",
    "        out = [d1, d2]\n",
    "        data.append(out)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data, columns= ['alleles_dist_ipscore_unrel', 'alleles_dist_hipsci_fib'], index = info.index)\n",
    "    \n",
    "    cols = ['diploid_alleles_ipscore_unrel', 'diploid_alleles_hipsci_fib']\n",
    "    df = df.join(info[cols])\n",
    "    return df\n",
    "\n",
    "def prepare_info_v1_batch(info):\n",
    "    cols = ['alleles_distipscore_unr', 'alleles_disthipsci_fib', 'diploid_allelesipscore_unr','diploid_alleleshipsci_fib']\n",
    "    cols_rename = ['alleles_dist_ipscore_unrel', 'alleles_dist_hipsci_fib', 'diploid_alleles_ipscore_unrel','diploid_alleles_hipsci_fib']\n",
    "    \n",
    "    df_batch = info_v1[cols].copy()\n",
    "    df_batch.columns = cols_rename\n",
    "    return df_batch\n",
    "\n",
    "def filter_info_all_annot(df):\n",
    "    df = df[(df.FILTER_GSCNQUAL == False) & (df.somatic == False) & (df.primary_site == True) & (df.stitch_constituent==False) & (df.cnv_class != 'Non_Bi')].copy()\n",
    "    return df\n",
    "\n",
    "def calculate_chi_and_annotate_info(info):\n",
    "    df_batch = prepare_allele_dist_batch(info)\n",
    "    comp = compare_var_sites(df_batch, 'ipscore_unrel', 'hipsci_fib')\n",
    "    inds= comp[comp.filter_chi_p ==True].index.tolist()\n",
    "    info['filter_batch'] = False\n",
    "    info.loc[inds, 'filter_batch'] = True\n",
    "    info['batch_p'] = comp.chi_p\n",
    "    return comp, info\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HWE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hardy_weinberg_expectation(dist1):\n",
    "    keys = ['0/0', '0/1', '1/1']\n",
    "    vals1 = [dist1.get(i, 0) for i in keys]\n",
    "    dist = {i:dist1.get(i, 0) for i in keys}\n",
    "    tot = sum(vals1)\n",
    "    \n",
    "    try:\n",
    "        p = (2*dist['0/0'] + dist['0/1'])/(2*tot)\n",
    "    except:\n",
    "        print dist\n",
    "        return\n",
    "    q = 1 - p\n",
    "    \n",
    "    exp_AA = (p**2) * tot\n",
    "    exp_Aa = 2*p*q*tot\n",
    "    exp_aa = (q**2)*tot\n",
    "    \n",
    "    hw_exp = [exp_AA, exp_Aa, exp_aa]\n",
    "    return vals1, hw_exp\n",
    "\n",
    "def convert_dist_to_alleles(x, cnv_class = 'DUP'):\n",
    "    \n",
    "    convert_dict_del = {2: '0/0', 1: '0/1', 0: '1/1'}\n",
    "    convert_dict_dup = {2: '0/0', 3: '0/1', 4: '1/1'}\n",
    "    dict_out = {}\n",
    "    if cnv_class == 'DUP':\n",
    "        \n",
    "        for i in x.keys():\n",
    "            k = convert_dict_dup.get(i, False)\n",
    "            if not k:\n",
    "                return False\n",
    "            else:\n",
    "                dict_out[k] = x[i]\n",
    "        return dict_out\n",
    "                \n",
    "    if cnv_class == 'DEL':\n",
    "        for i in x.keys():\n",
    "            k = convert_dict_del.get(i, False)\n",
    "            if not k:\n",
    "                return False\n",
    "            else:\n",
    "                dict_out[k] = x[i]\n",
    "        return dict_out\n",
    "\n",
    "def prep_info_hwe(info):\n",
    "    info = info.copy()\n",
    "    info = info[info.cnv_class != 'Non_Bi']\n",
    "    info = info[(info.cnv_class != 'mCNV')]\n",
    "    info = info[~info.Chr.isin(['X', 'Y'])]\n",
    "    return info\n",
    "\n",
    "def get_hwe_chi_comparison_pval(dist):\n",
    "    \n",
    "    obs, hwe = hardy_weinberg_expectation(dist)\n",
    "    inds = get_non_zero_inds(obs, hwe)\n",
    "    obs_test, hwe_test = (subset_list(obs, inds), subset_list(hwe, inds))\n",
    "    s = stats.chisquare(obs_test, f_exp=hwe_test)\n",
    "    p_val = s.pvalue\n",
    "    \n",
    "    return p_val\n",
    "\n",
    "def get_non_zero_inds(l1, l2):\n",
    "    nz1 = [i for i,l in list(enumerate(l1)) if l !=0]\n",
    "    nz2 = [i for i,l in list(enumerate(l2)) if l !=0]\n",
    "    inds_to_test = list(set(nz1 + nz2))    \n",
    "    return inds_to_test\n",
    "\n",
    "def subset_list(l, inds):\n",
    "    return [l[i] for i in inds]\n",
    "\n",
    "def calculate_hwe_and_annotate_info(info_hwe, info):\n",
    "\n",
    "#     info_hwe['allele_dist_hwe_corrected'] = info_hwe.alleles_dist.apply(lambda x: convert_dist_to_alleles(x,cnv_class))\n",
    "    \n",
    "    data = []\n",
    "    for i, x in info_hwe.iterrows():\n",
    "    \n",
    "        dist_all = x['allele_dist_hwe_corrected']\n",
    "        site = i\n",
    "        p_val_all = get_hwe_chi_comparison_pval(dist_all)\n",
    "\n",
    "        data.append(p_val_all)\n",
    "\n",
    "\n",
    "    inds = info_hwe.index.tolist()\n",
    "    cols =['hwe_p']\n",
    "    hwe = pd.DataFrame(data, index=inds, columns=cols)\n",
    "    hwe_p_thresh = 0.05 / hwe.shape[0]\n",
    "    hwe['filter_hwe'] = hwe.hwe_p < hwe_p_thresh\n",
    "    info_hwe['filter_hwe'] = hwe.filter_hwe\n",
    "    \n",
    "    inds = hwe[hwe.filter_hwe].index.tolist()\n",
    "    info['filter_hwe'] = False\n",
    "    info.loc[inds, 'filter_hwe'] = True\n",
    "    info['hwe_p'] = hwe.hwe_p\n",
    "    # these weren't tested because they were mCNV or non-simple DUP\n",
    "    info['hwe_p'] = info.hwe_p.fillna(False)\n",
    "    return info_hwe, hwe, info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_hwe_annotations(info_v3):\n",
    "    info_hwe = info_v3.pipe(prep_info_hwe)\n",
    "\n",
    "    info_hwe['alleles_str'] = info_hwe.diploid_alleles.apply(lambda x: \",\".join([str(i) for i in x]))\n",
    "\n",
    "    info_hwe_del = info_hwe[info_hwe.cnv_class == 'DEL'].copy()\n",
    "    info_hwe_del['allele_dist_hwe_corrected'] = info_hwe_del.alleles_dist.apply(lambda x: convert_dist_to_alleles(x, 'DEL'))\n",
    "\n",
    "    info_hwe_dup = info_hwe[info_hwe.cnv_class == 'DUP'].copy()\n",
    "    info_hwe_dup['allele_dist_hwe_corrected'] = info_hwe_dup.alleles_dist.apply(lambda x: convert_dist_to_alleles(x, 'DUP'))\n",
    "\n",
    "    info_hwe_dup = info_hwe_dup[info_hwe_dup.allele_dist_hwe_corrected != False]\n",
    "\n",
    "    info_hwe_testing = pd.concat([info_hwe_dup, info_hwe_del])\n",
    "    info_hwe_testing, hwe, info_v3 = calculate_hwe_and_annotate_info(info_hwe_testing, info_v3)\n",
    "    return hwe, info_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_arguments_to_parser(parser):\n",
    "    \n",
    "    parser.add_argument(\"-cns\", \"--cns\", dest=\"cns\", metavar='<cns>', help=\"genome strip cns pickle (Copy Number States)\", required=True)\n",
    "    \n",
    "    parser.add_argument(\"-info\", \"--info\", dest=\"info\", metavar='<info>', help=\"genome strip info pickle\", required=True)\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"-o\", \"--output_dir\", dest=\"output_dir\", metavar='<out_dir>', help=\"output directory for summary output\", required=True)\n",
    "    \n",
    "\n",
    "    parser.add_argument(\"-file_suff\", \"--suffix\", dest=\"suffix\", metavar='<suffix>', help=\"prefix to name files\", default = False)\n",
    "    \n",
    "\n",
    "    parser.set_defaults(entry_point=run_from_args)\n",
    "\n",
    "def command_parser():\n",
    "    parser = argparse.ArgumentParser(description= 'command line tool to compute hwe and batch effects for genome strip variants')\n",
    "    \n",
    "    add_arguments_to_parser(parser)\n",
    "    return parser\n",
    "\n",
    "def run_from_args(args):\n",
    "    gs_info = pd.read_pickle(args.info)\n",
    "    print 'Testing batch and hwe of gs variants'\n",
    "    print CM.datestring(hour=True, minute=True)\n",
    "   \n",
    "    comp, gs_info = calculate_chi_and_annotate_info(gs_info)\n",
    "    hwe, gs_info = run_hwe_annotations(gs_info)\n",
    "    \n",
    "    comp['ID'] = comp.index\n",
    "    hwe['ID'] = hwe.index\n",
    "    \n",
    "    stats = pd.merge(comp, hwe, how = 'outer')\n",
    "    \n",
    "    output_location = args.output_dir\n",
    "    if args.suffix:\n",
    "        fn_info = os.path.join(output_location, 'gs_info' + args.suffix)      \n",
    "        var_name_info = 'gs_info' + args.suffix\n",
    "        var_name_stats = 'gs_qc_stats' + args.suffix\n",
    "       \n",
    "       \n",
    "    else:\n",
    "        fn_info = os.path.join(output_location, 'gs_info')\n",
    "        fn_cns = os.path.join(output_location, 'gs_cns')\n",
    "        var_name_info = 'gs_info'\n",
    "        var_name_stats = 'gs_qc_stats' \n",
    "        \n",
    "    \n",
    "    print 'data annotated'\n",
    "    print CM.datestring(hour=True, minute=True)\n",
    "    \n",
    "    CM.save_dataframe(var_name_stats, stats, output_location, print_vars_recorded_loc=False)\n",
    "    CM.save_dataframe(var_name_info, gs_info, output_location, print_vars_recorded_loc=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = command_parser()\n",
    "    args = parser.parse_args()\n",
    "    sys.exit(args.entry_point(args))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
