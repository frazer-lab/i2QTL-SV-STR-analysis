{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/frazer01/home/djakubosky/software/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "from subprocess import call\n",
    "import subprocess\n",
    "import glob\n",
    "import djPyBio as DJ\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import pybedtools\n",
    "import itertools\n",
    "import glob\n",
    "pd.set_option('display.max_columns', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datestring(month=True, day=True, year=True, hour=False, minute=False):\n",
    "    d = datetime\n",
    "    \n",
    "    y = str(d.datetime.now().timetuple().tm_year)\n",
    "    m =  str(d.datetime.now().timetuple().tm_mon)\n",
    "    D = str(d.datetime.now().timetuple().tm_mday)\n",
    "    h = str(d.datetime.now().timetuple().tm_hour)\n",
    "    mins = str(d.datetime.now().timetuple().tm_min)\n",
    "    \n",
    "    if int(month) in range(0,10):\n",
    "        m = \"0\" + m\n",
    "    \n",
    "    \n",
    "    dt_array = [y, m, D, h, mins]\n",
    "    t_f_array = [year, month, day, hour, minute]\n",
    "    \n",
    "    Date_Array = []\n",
    "    for s, i, in zip(dt_array, t_f_array):\n",
    "        if i == True:\n",
    "            Date_Array.append(s)\n",
    "    \n",
    "    return '_'.join(Date_Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def qstat_u_df(user):\n",
    "    \"\"\" Takes a qstat for a user, parses, and returns\n",
    "    pandas dataframe\"\"\"\n",
    "    \n",
    "    command = ['qstat', '-u', user]\n",
    "    out = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "    lines = []\n",
    "    for line in out.stdout:\n",
    "        lines.append(line.rstrip())\n",
    "    head = lines[0]\n",
    "    head = head.split(' ')\n",
    "    head = filter(None, head)\n",
    "    lines = lines[2:]\n",
    "    for x,y in enumerate(lines):\n",
    " \n",
    "        lines[x] = y.split(' ')\n",
    "        lines[x] = filter(None, lines[x])\n",
    "        if len(lines[x]) < len(head):\n",
    "            lines[x].append(np.NaN)\n",
    "    \n",
    "    for x, y in enumerate(lines):\n",
    "        state = y[4]\n",
    "    \n",
    "        if state == 'qw' or state =='hqw':\n",
    "        \n",
    "            out = y[0:7]\n",
    "            slots= y[7:]\n",
    "            lines[x] = out + ['Unknown'] + slots\n",
    "        \n",
    "    df = pd.DataFrame(lines, columns=head)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-ID</th>\n",
       "      <th>prior</th>\n",
       "      <th>name</th>\n",
       "      <th>user</th>\n",
       "      <th>state</th>\n",
       "      <th>submit/start</th>\n",
       "      <th>at</th>\n",
       "      <th>queue</th>\n",
       "      <th>slots</th>\n",
       "      <th>ja-task-ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668009</td>\n",
       "      <td>0.55617</td>\n",
       "      <td>align_38_t</td>\n",
       "      <td>joreyna</td>\n",
       "      <td>r</td>\n",
       "      <td>04/15/2016</td>\n",
       "      <td>16:13:28</td>\n",
       "      <td>week.q@fl-n-1-10</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>668012</td>\n",
       "      <td>0.55617</td>\n",
       "      <td>align_37_t</td>\n",
       "      <td>joreyna</td>\n",
       "      <td>r</td>\n",
       "      <td>04/15/2016</td>\n",
       "      <td>16:31:58</td>\n",
       "      <td>week.q@fl-n-1-5</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>668011</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>compress_3</td>\n",
       "      <td>joreyna</td>\n",
       "      <td>hqw</td>\n",
       "      <td>04/15/2016</td>\n",
       "      <td>16:06:43</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>668013</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>compress_3</td>\n",
       "      <td>joreyna</td>\n",
       "      <td>hqw</td>\n",
       "      <td>04/15/2016</td>\n",
       "      <td>16:08:30</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job-ID    prior        name     user state submit/start        at  \\\n",
       "0  668009  0.55617  align_38_t  joreyna     r   04/15/2016  16:13:28   \n",
       "1  668012  0.55617  align_37_t  joreyna     r   04/15/2016  16:31:58   \n",
       "2  668011  0.00000  compress_3  joreyna   hqw   04/15/2016  16:06:43   \n",
       "3  668013  0.00000  compress_3  joreyna   hqw   04/15/2016  16:08:30   \n",
       "\n",
       "              queue slots  ja-task-ID  \n",
       "0  week.q@fl-n-1-10    32         NaN  \n",
       "1   week.q@fl-n-1-5    32         NaN  \n",
       "2           Unknown    32         NaN  \n",
       "3           Unknown    32         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qstat_u_df('joreyna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def qstat_u_r_df(user):\n",
    "    \n",
    "    \"\"\" Returns Data_Frame with full info about job_names and resources\n",
    "    needs to be developed for special categories, works with genome strip \n",
    "    jobs\"\"\"\n",
    "    \n",
    "    command = ['qstat', '-r', '-u', user]\n",
    "    out = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "    lines = []\n",
    "    for line in out.stdout:\n",
    "        lines.append(line.rstrip())\n",
    "        \n",
    "    jobs = True\n",
    "    try:\n",
    " \n",
    "        head = lines[0]\n",
    "        head = head.split(' ')\n",
    "        head = filter(None, head)\n",
    "        lines = lines[2:]\n",
    "    except:\n",
    "        jobs = False\n",
    "        \n",
    "        print 'No Jobs Running'\n",
    "        \n",
    "    \n",
    "    if jobs==True:\n",
    "        \n",
    "    \n",
    "        for x,y in enumerate(lines):\n",
    "     \n",
    "            lines[x] = y.split(' ')\n",
    "            lines[x] = filter(None, lines[x])\n",
    "        \n",
    "        counter = 0\n",
    "        data = []\n",
    "        headers = ['job_ID', 'priority', 'user',\n",
    "                  'status', 'date', 'time_start',\n",
    "                  'queue', 'slots', 'job_name', \n",
    "                  'h_vmem']\n",
    "        \n",
    "        OUT = []\n",
    "        \n",
    "        \n",
    "        # collapse the lines into their states\n",
    "        \n",
    "        queued = []\n",
    "        running = []\n",
    "        \n",
    "        for x,y in enumerate(lines):\n",
    "            line_pairs =[]\n",
    "                 \n",
    "            try:\n",
    "                if lines[x][4] == 'r':\n",
    "                    \n",
    "    #  add in support for Requested PE/Granted PE here\n",
    "                    running_line = True\n",
    "                    running.append(list(itertools.chain(*lines[x:x+6])))\n",
    "                elif lines[x][4]=='qw':\n",
    "                    queued.append(list(itertools.chain(*lines[x:x+5])))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        for x in running:\n",
    "            job_ID = x[0]\n",
    "            prior = x[1]\n",
    "            user = x[3]\n",
    "            status = x[4]\n",
    "            d = x[5]\n",
    "            time_start = x[6]\n",
    "            queue = x[7]\n",
    "            slots = x[8]\n",
    "            job_name = x[11]\n",
    "            h_vmem=x[17].split('=')[1]\n",
    "            row = [job_ID,prior,user,status,d,time_start, queue,\n",
    "            slots,job_name,h_vmem]\n",
    "            data.append(row)\n",
    "      \n",
    "            \n",
    "        for x in queued:\n",
    "            job_ID = x[0]\n",
    "            prior = x[1]\n",
    "            user = x[3]\n",
    "            status = x[4]\n",
    "            d = x[5]\n",
    "            time_start = x[6]\n",
    "            queue = np.NaN\n",
    "            slots = x[7]\n",
    "            job_name = x[10]\n",
    "            h_vmem = x[13]\n",
    "            row = [job_ID,prior,user,status,d,time_start, queue,\n",
    "            slots,job_name,h_vmem]\n",
    "            data.append(row)\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        df = pd.DataFrame(data,columns=headers)\n",
    "                \n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGE_Header(jobname, queue, h_vmem, cores, out, err):\n",
    "    \"\"\"\n",
    "    USAGE: SGE_Header(jobname, queue, h_vmem, cores, out, err)'\n",
    "    \"\"\"\n",
    " \n",
    "        \n",
    "    if queue <> \"all\":\n",
    "        Header = \"#!/bin/bash\" + \"\\n\" \\\n",
    "        + \"#$ -N \" + jobname + \"\\n\" \\\n",
    "        + \"#$ -l h_vmem=\" + h_vmem + \"\\n\" \\\n",
    "        + \"#$ -l \" + queue + \"\\n\" \\\n",
    "        + \"#$ -pe smp \" + cores + \"\\n\" \\\n",
    "        + \"#$ -V\" + \"\\n\" \\\n",
    "        + \"#$ -e \" + err + \"\\n\" \\\n",
    "        + \"#$ -o \" + out\n",
    "    else:\n",
    "        Header = \"#!/bin/bash\" + \"\\n\" \\\n",
    "        + \"#$ -N \" + jobname + \"\\n\" \\\n",
    "        + \"#$ -l h_vmem=\" + h_vmem + \"\\n\" \\\n",
    "        + \"#$ -pe smp \" + cores + \"\\n\" \\\n",
    "        + \"#$ -V\" + \"\\n\" \\\n",
    "        + \"#$ -e \" + err + \"\\n\" \\\n",
    "        + \"#$ -o \" + out\n",
    "    return Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_OL_Column_RO_Calls(df1, df2, overlap=0.5, vcf_format=True):\n",
    "    \"\"\" Takes data frames with chr, start, end as input, converts to pybedtools\n",
    "    performs reciprocal overlap analysis\n",
    "    \n",
    "    returns df of true/false and overlap percent with index of df1 (df)\n",
    "    returns dataframe of bedtools overlap output (Z)\n",
    "    \n",
    "    if vcf_format = True, converts df1 from VCF format to properly formatted\n",
    "    pandas df\n",
    "    \n",
    "    overlap: sets reciprocal overlap thresholds (default = 0.5)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Header_original = df1.columns.tolist()\n",
    "    \n",
    "    Remove_col = ['CHROM', 'POS', 'END','ID']\n",
    "    \n",
    "    if vcf_format:\n",
    "        \n",
    "## Fix the dataframe order if in VCF file format to make sure it can be \n",
    "## turned into a pybedtool\n",
    "\n",
    "        for x in Remove_col:\n",
    "            try:\n",
    "                Header_original.remove(x)\n",
    "            except:\n",
    "                print x\n",
    "        HEAD = Remove_col+ Header_original\n",
    "    if not vcf_format:\n",
    "        HEAD = Header_original\n",
    "\n",
    "    df1=df1[HEAD]\n",
    "    \n",
    "## Modify the header names to attribute to A or B bedtools \n",
    "\n",
    "\n",
    "    Heading_1 = Header_list(df1.columns.tolist(),'A')\n",
    "    Heading_2 = Header_list(df2.columns.tolist(), 'B')\n",
    "    \n",
    "## New Header for bedtool intersect -wo output dataframes\n",
    "\n",
    "    Out_Head = Heading_1 + Heading_2 + ['Overlap']\n",
    "\n",
    "    \n",
    "    BT_B = pybedtools.BedTool.from_dataframe(df2)\n",
    "    BT_A = pybedtools.BedTool.from_dataframe(df1)\n",
    "\n",
    "    \n",
    "    Z = pd.read_table(BT_A.intersect(BT_B, f=overlap, F=overlap, wo=True).fn, names=Out_Head)\n",
    "    Z = Z.convert_objects(convert_numeric=True)\n",
    "    df = pd.DataFrame(0, index = df1.Coords, columns=['Overlap', 'Percent_A', 'Percent_B'])\n",
    "    Z['Percent_A'] = Z.Overlap/(Z.End_A - Z.Start_A)\n",
    "    Z['Percent_B'] = Z.Overlap/(Z.End_B - Z.Start_B)\n",
    "    df['Overlap'] = 'False'\n",
    "\n",
    "    ind = 0        \n",
    "    for x in Z.Coords_A:\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            df.ix[x,'Overlap']= 'True'\n",
    "            df.ix[x, 'Percent_A']= Z.ix[ind,'Percent_A']\n",
    "            df.ix[x, 'Percent_B']= Z.ix[ind,'Percent_B']\n",
    "            ind += 1 \n",
    "        except:\n",
    "            print x\n",
    "    return df, Z, Out_Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svviz_command(family, svtype, region, out_file):\n",
    "    Fam = family\n",
    "    Fam_Spl = Fam.split('_')\n",
    "    bams = []\n",
    "    \n",
    "    Coords = ''\n",
    "    \n",
    "    reg_spl = region.split('_')\n",
    "    for x in reg_spl:\n",
    "        Chr = reg_spl[1]\n",
    "        Start = reg_spl[2]\n",
    "        End = reg_spl[3]\n",
    "        Coords = \" \".join([Chr,Start,End])\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in Fam_Spl:\n",
    "        UUID = Subj_dict[x]\n",
    "        bam_loc = '/frazer01/projects/CARDIPS/pipeline/WGS/alignment_bwa/' + UUID + '/' + UUID + '.mdup.bam'\n",
    "        \n",
    "        bams.append(bam_loc)\n",
    "        \n",
    "        \n",
    "    child = bams[0]\n",
    "    father = bams[1]\n",
    "    mother = bams[2]\n",
    "    \n",
    "    reference = '/frazer01/publicdata/gatk_bundle_2.8/b37/human_g1k_v37_decoy_Sendai.fasta'\n",
    "    command = 'svviz -t ' + svtype + ' -b ' + child + \\\n",
    "    ' -b ' + father + ' -b ' + mother + \" \" + reference + \" \" + Coords + \\\n",
    "    ' --export ' + out_file\n",
    "     \n",
    "    \n",
    "    print command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
